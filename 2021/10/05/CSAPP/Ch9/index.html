<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Ch9 | RainbowBin</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });  Virtual Memory">
<meta property="og:type" content="article">
<meta property="og:title" content="Ch9">
<meta property="og:url" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/index.html">
<meta property="og:site_name" content="RainbowBin">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });  Virtual Memory">
<meta property="og:locale">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/PA.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/VA.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/Vmsys.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/pagetable.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/pagefault.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/alloca.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/MM.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/mmcontrol.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/symbols.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/addresstrans.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/operations.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/cachePA.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/tlb.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/tlboperation.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/multPT.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/addrtrans.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/pagetable.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/level4addr.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/memspace.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/taskstruct.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/pagefaulthandler.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/sharedobj.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/privateobj.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/override.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/mmp.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/mallocexample.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/heapblock.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/simplelistorg.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/boundarytag.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/coalesce.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/explicitexample.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/segregatelist.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/graph.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/marksweep.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/dealwithbugs.png">
<meta property="article:published_time" content="2021-10-05T04:10:53.000Z">
<meta property="article:modified_time" content="2021-10-09T02:27:15.931Z">
<meta property="article:author" content="rubbish">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/PA.png">
  
    <link rel="alternate" href="/atom.xml" title="RainbowBin" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">RainbowBin</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://rubbish-and-world.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CSAPP/Ch9" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/10/05/CSAPP/Ch9/" class="article-date">
  <time class="dt-published" datetime="2021-10-05T04:10:53.000Z" itemprop="datePublished">2021-10-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/csapp/">csapp</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Ch9
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });</script>

<h1 id="Virtual-Memory"><a href="#Virtual-Memory" class="headerlink" title="Virtual Memory"></a>Virtual Memory</h1><a id="more"></a>

<p><em>virtual memory provides three important capabilities</em></p>
<ul>
<li>Uses main memory efficiently by treating it as a cache for an address space stored on disk, keeping only the active areas in main memory and transferring data back and forth between disk and memory as needed</li>
<li>It simplifies memory management by providing each process with a uniform address space.</li>
<li>It protects the address space of each process from corruption by other processes.(Each process has its own page table)</li>
</ul>
<p>A major reason for its success is that it works <strong>silently and automatically, without any intervention from the application programmer</strong></p>
<h2 id="9-1-Physical-and-Virtual-Addressing"><a href="#9-1-Physical-and-Virtual-Addressing" class="headerlink" title="9.1 Physical and Virtual Addressing"></a>9.1 Physical and Virtual Addressing</h2><p><em>Physical : The main memory of a computer system is organized as an array of <code>M </code> contiguous byte-size cells. Each byte has a unique physical address . The first byte has an address of 0</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/PA.png" alt="Physical Addressing"></p>
<p><em>Virtual : the CPU accesses main memory by generating a virtual address, which is converted to the appropriate physical address before being sent to main memory. The task of converting a virtual address to a physical one is known as address translation</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/VA.png" alt="Vitual Addressing"></p>
<h2 id="9-2-Address-Spaces"><a href="#9-2-Address-Spaces" class="headerlink" title="9.2 Address Spaces"></a>9.2 Address Spaces</h2><p><em>An address space is an ordered set of nonnegative integer addresses {0, 1, 2,…}</em></p>
<p>If the integers in the address space are consecutive, then we say that it is a <strong>linear address space.</strong></p>
<h4 id="Virtual-Memory-Space"><a href="#Virtual-Memory-Space" class="headerlink" title="Virtual Memory Space"></a>Virtual Memory Space</h4><p>$$<br>{ 0,1,2,…,N-1} , N=2^n<br>$$</p>
<ul>
<li>n is the number of bits can be used to represent addresses(width of address bus)</li>
<li>In modern system, n is either 32 or 64</li>
</ul>
<h4 id="Phiscal-Memory-Space"><a href="#Phiscal-Memory-Space" class="headerlink" title="Phiscal Memory Space"></a>Phiscal Memory Space</h4><p>$$<br>{0,1,2,…,M-1}<br>$$</p>
<ul>
<li>M doesn’t need to be power of 2</li>
<li>M is the number of bytes we acutally have in memory</li>
</ul>
<h4 id="Basic-Concept-of-Virtual-Memory"><a href="#Basic-Concept-of-Virtual-Memory" class="headerlink" title="Basic Concept of Virtual Memory"></a>Basic Concept of Virtual Memory</h4><p><strong><em>Allow each data object to have multiple independent addresses, each chosen from a different address space.</em></strong></p>
<p>(Each byte of main memory has a virtual address chosen from the virtual address space, and a physical address chosen from the physical address space.)</p>
<h2 id="9-3-VM-as-a-Tool-for-Caching"><a href="#9-3-VM-as-a-Tool-for-Caching" class="headerlink" title="9.3 VM as a Tool for Caching"></a>9.3 VM as a Tool for Caching</h2><p><em>Conceptually, a virtual memory is organized as an array of N contiguous byte-size cells stored on <strong>disk</strong></em></p>
<ul>
<li>The contents of the array on disk are cached in main memory</li>
<li>The system partitioning the virtual memory into fixed-size blocks called <strong>virtual pages</strong>, P bytes per page</li>
<li>Physical memory is partitioned into <strong>physical pages</strong> , also P bytes in size</li>
</ul>
<p>At any point in time, <strong>the set of virtual pages</strong> is partitioned into three <strong>disjoint subsets</strong>:</p>
<ul>
<li>Unallocated. <ul>
<li>Pages that have not yet been allocated (or created) by the VM system. </li>
<li>Unallocated blocks do not have any data associated with them, and thus do not occupy any space on disk.</li>
</ul>
</li>
<li>Cached<ul>
<li>Allocated pages that are currently cached in physical memory</li>
</ul>
</li>
<li>Uncached. <ul>
<li>Allocated pages that are not cached in physical memory</li>
</ul>
</li>
</ul>
<p><img src="/2021/10/05/CSAPP/Ch9/Vmsys.png" alt="Virtual Memory System"></p>
<h3 id="9-3-1-DRAM-Cache-Organization"><a href="#9-3-1-DRAM-Cache-Organization" class="headerlink" title="9.3.1 DRAM Cache Organization"></a>9.3.1 DRAM Cache Organization</h3><p><em>the organization of the DRAM cache is <strong>driven entirely by the enormous cost of misses</strong></em></p>
<ul>
<li>Because of the large miss penalty and the expense of accessing the first byte, <strong>virtual pages tend to be large</strong>—typically 4 KB to 2 MB</li>
<li>Due to the large miss penalty, DRAM caches are <strong>fully associative</strong><ul>
<li>Only one set, any virtual page can be placed in any physical page</li>
</ul>
</li>
<li>Operating systems use much more <strong>sophisticated replacement algorithms</strong> for DRAM caches than the hardware does for SRAM caches.</li>
<li>Because of the large access time of disk, DRAM caches always use <strong>write-back</strong> instead of write-through.</li>
</ul>
<h3 id="9-3-2-Page-Tables"><a href="#9-3-2-Page-Tables" class="headerlink" title="9.3.2 Page Tables"></a>9.3.2 Page Tables</h3><p>The address translation hardware reads the page table each time it converts a virtual address to a physical address. </p>
<p>The operating system is responsible for maintaining the contents of the page table and transferring pages back and forth between disk and DRAM.</p>
<p><img src="/2021/10/05/CSAPP/Ch9/pagetable.png" alt="page table"></p>
<ul>
<li>A page table is an array of page table entries (PTEs)</li>
<li>Each page in the virtual address space has a PTE at a fixed offset in the page table.</li>
<li>If the valid bit is set, the address field indicates the start of the corresponding physical page in DRAM where the virtual page is cached</li>
</ul>
<h4 id="Practice-Problem-9-2"><a href="#Practice-Problem-9-2" class="headerlink" title="Practice Problem 9.2"></a>Practice Problem 9.2</h4><blockquote>
<p>Determine the number of page table entries (PTEs) that are needed for the following combinations of virtual address size (n) and page size (P):</p>
<table>
<thead>
<tr>
<th>n</th>
<th>$P=2^p$</th>
<th>Number of PTEs</th>
</tr>
</thead>
<tbody><tr>
<td>12</td>
<td>1K</td>
<td></td>
</tr>
<tr>
<td>16</td>
<td>16K</td>
<td></td>
</tr>
<tr>
<td>24</td>
<td>2M</td>
<td></td>
</tr>
<tr>
<td>36</td>
<td>1G</td>
<td></td>
</tr>
</tbody></table>
</blockquote>
<h4 id="My-solution-white-check-mark"><a href="#My-solution-white-check-mark" class="headerlink" title="My solution : :white_check_mark:"></a>My solution : :white_check_mark:</h4><p>$$<br>2^n / P = 2^{n-p}<br>$$</p>
<table>
<thead>
<tr>
<th>n</th>
<th>$P=2^p$</th>
<th>Number of PTEs</th>
</tr>
</thead>
<tbody><tr>
<td>12</td>
<td>1K</td>
<td>4</td>
</tr>
<tr>
<td>16</td>
<td>16K</td>
<td>4</td>
</tr>
<tr>
<td>24</td>
<td>2M</td>
<td>8</td>
</tr>
<tr>
<td>36</td>
<td>1G</td>
<td>64</td>
</tr>
</tbody></table>
<h3 id="9-3-3-Page-Hits"><a href="#9-3-3-Page-Hits" class="headerlink" title="9.3.3 Page Hits"></a>9.3.3 Page Hits</h3><h3 id="9-3-4-Page-Faults"><a href="#9-3-4-Page-Faults" class="headerlink" title="9.3.4 Page Faults"></a>9.3.4 Page Faults</h3><p><em>A DRAM cache miss is known as a page fault.</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/pagefault.png" alt="page fault"></p>
<h3 id="9-3-5-Allocating-Pages"><a href="#9-3-5-Allocating-Pages" class="headerlink" title="9.3.5 Allocating Pages"></a>9.3.5 Allocating Pages</h3><p><em>Figure 9.8 shows the effect on our example page table when the operating system allocates a new page of virtual memory—for example, as a result of calling malloc.</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/alloca.png" alt="allocate new page"></p>
<h3 id="9-3-6-Locality-to-the-Rescue-Again"><a href="#9-3-6-Locality-to-the-Rescue-Again" class="headerlink" title="9.3.6 Locality to the Rescue Again"></a>9.3.6 Locality to the Rescue Again</h3><p><em>In practice, virtual memory works well, mainly because of locality.</em></p>
<blockquote>
<p>Counting page faults </p>
<p>You can monitor the number of page faults (and lots of other information) with the Linux <code>getrusage</code> function</p>
</blockquote>
<h2 id="9-4-VM-as-a-Tool-for-Memory-Management"><a href="#9-4-VM-as-a-Tool-for-Memory-Management" class="headerlink" title="9.4 VM as a Tool for Memory Management"></a>9.4 VM as a Tool for Memory Management</h2><p><em>In fact, operating systems provide a separate page table, and thus a separate virtual address space, for each process.</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/MM.png" alt="Memory Management"></p>
<p> In particular, VM <strong>simplifies linking and loading, the sharing of code and data, and allocating memory to application</strong></p>
<h4 id="Simplifying-linking"><a href="#Simplifying-linking" class="headerlink" title="Simplifying linking"></a>Simplifying linking</h4><ul>
<li>A separate address space allows each process to use the same basic format for its memory image, regardless of where the code and data actually reside in physical memory</li>
</ul>
<h4 id="Simplifying-loading"><a href="#Simplifying-loading" class="headerlink" title="Simplifying loading."></a>Simplifying loading.</h4><ul>
<li>To load the .text and .data sections of an object file into a newly created process, the Linux loader <strong>allocates virtual pages for the code and data segments, marks them as invalid</strong> (i.e., not cached), and <strong>points their page table entries to the appropriate locations in the object file.</strong></li>
<li><strong>the loader never actually copies</strong> any data from disk into memory</li>
<li> The data are paged in automatically and on demand by the virtual memory system the first time each page is referenced(Copying is done by the OS)</li>
</ul>
<h4 id="Simplifying-sharing"><a href="#Simplifying-sharing" class="headerlink" title="Simplifying sharing"></a>Simplifying sharing</h4><ul>
<li>For unique resources like user-stack, program code, the operating system creates page tables that <strong>map the corresponding virtual pages to disjoint physical pages.</strong></li>
<li>For shared resources like shared libraries, the operating system can arrange for multiple processes to share a single copy of this code by <strong>mapping the appropriate virtual pages in different processes to the same physical page</strong></li>
</ul>
<h4 id="Simplifying-memory-allocation"><a href="#Simplifying-memory-allocation" class="headerlink" title="Simplifying memory allocation"></a>Simplifying memory allocation</h4><ul>
<li>Because of the way page tables work, there is no need for the operating system to locate several contiguous pages of physical memory. The pages can be scattered randomly in physical memory.</li>
</ul>
<h2 id="9-5-VM-as-a-Tool-for-Memory-Protection"><a href="#9-5-VM-as-a-Tool-for-Memory-Protection" class="headerlink" title="9.5 VM as a Tool for Memory Protection"></a>9.5 VM as a Tool for Memory Protection</h2><p><em>Providing separate virtual address spaces makes it easy to isolate the private memories of different processes. But the <strong>address translation mechanism can be extended in a natural way to provide even finer access control</strong>.</em></p>
<p>Since the address translation hardware reads a PTE each time the CPU generates an address, it is straightforward to control access to the contents of a virtual page by adding some additional <strong>permission bits</strong> to the PTE. </p>
<p><img src="/2021/10/05/CSAPP/Ch9/mmcontrol.png" alt="Memory Control"></p>
<h2 id="9-6-Address-Translation"><a href="#9-6-Address-Translation" class="headerlink" title="9.6 Address Translation"></a>9.6 Address Translation</h2><p><em>This section is going to explain how hardware work in address translation, but ignoring some details like timing</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/symbols.png" alt="symbols"></p>
<p>Formally, address translation is <strong><em>a mapping between the elements of an N element virtual address space (VAS) and an M element physical address space (PAS)</em></strong><br>$$<br>MAP:VAS\rightarrow PAS \cup \O<br>$$<br><img src="/2021/10/05/CSAPP/Ch9/addresstrans.png" alt="Address translation"></p>
<ul>
<li>A control register in the CPU, the page table base register (PTBR) points to the current page table.</li>
<li>The n-bit virtual address has two components: <ul>
<li>$p$ bits <strong>virtual page offset</strong> (VPO)</li>
<li>$(n − p)$ bits <strong>virtual page number</strong> (VPN).</li>
</ul>
</li>
<li>The MMU <strong>uses the VPN to select the appropriate PTE</strong>. For example, VPN 0 selects PTE 0, VPN 1 selects PTE 1, and so on</li>
<li>The corresponding physical address is the <strong>concatenation of the physical page number (PPN)from the page table entry and the VPO from the virtual address.</strong></li>
<li>Notice that since the physical and virtual pages are both P bytes, the physical page offset (PPO)is identical to the VPO.</li>
</ul>
<h4 id="Page-hit-and-Page-fault"><a href="#Page-hit-and-Page-fault" class="headerlink" title="Page hit and Page fault"></a>Page hit and Page fault</h4><p><img src="/2021/10/05/CSAPP/Ch9/operations.png" alt="page operation"></p>
<h5 id="Page-hit"><a href="#Page-hit" class="headerlink" title="Page hit"></a>Page hit</h5><ol>
<li>The processor generates a virtual address and sends it to the MMU.</li>
<li>The MMU generates the PTE address and requests it from the cache/ main memory.</li>
<li>The cache/main memory returns the PTE to the MMU.</li>
<li>The MMU constructs the physical address and sends it to the cache/main memory.</li>
<li>The cache/main memory returns the requested data word to the processor.</li>
</ol>
<h5 id="Page-fault"><a href="#Page-fault" class="headerlink" title="Page fault"></a>Page fault</h5><p>The same as steps 1 to 3  in page hit</p>
<ol start="4">
<li>The valid bit in the PTE is zero, so the MMU triggers an exception, which transfers control in the CPU to a page fault exception handler in the operating system kernel.</li>
<li>The fault handler identifies a victim page in physical memory, and if that page has been modified, pages it out to disk.</li>
<li>The fault handler pages in the new page and updates the PTE in memory</li>
<li>The fault handler returns to the original process, causing the faulting instruction to be restarted. The CPU resends the offending virtual address to the MMU. Because the virtual page is now cached in physical memory, there is a hit, and after the MMU performs the steps in Figure 9.13(a), the main memory returns the requested word to the processor.</li>
</ol>
<h4 id="Practice-Problem-9-3"><a href="#Practice-Problem-9-3" class="headerlink" title="Practice Problem 9.3"></a>Practice Problem 9.3</h4><blockquote>
<p>Given a 64-bit virtual address space and a 32-bit physical address, determine the number of bits in the VPN, VPO, PPN, and PPO for the following page sizes P:</p>
<table>
<thead>
<tr>
<th>P</th>
<th>(number of)VPN bits</th>
<th>VPO bits</th>
<th>PPN bits</th>
<th>PPO bits</th>
</tr>
</thead>
<tbody><tr>
<td>1kb</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2kb</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>4kb</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>16kb</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
</blockquote>
<h4 id="My-solution-white-check-mark-1"><a href="#My-solution-white-check-mark-1" class="headerlink" title="My solution : :white_check_mark:"></a>My solution : :white_check_mark:</h4><p>$$<br>2^{64} \div 2^{10} = 2^{54} (\text{pages})<br>$$</p>
<p>$$<br>VPN=54(bits)<br>$$</p>
<table>
<thead>
<tr>
<th>P</th>
<th>(number of)VPN bits</th>
<th>VPO bits</th>
<th>PPN bits</th>
<th>PPO bits</th>
</tr>
</thead>
<tbody><tr>
<td>1kb</td>
<td>54</td>
<td>10</td>
<td>22</td>
<td>10</td>
</tr>
<tr>
<td>2kb</td>
<td>53</td>
<td>11</td>
<td>21</td>
<td>11</td>
</tr>
<tr>
<td>4kb</td>
<td>52</td>
<td>12</td>
<td>20</td>
<td>12</td>
</tr>
<tr>
<td>16kb</td>
<td>50</td>
<td>14</td>
<td>18</td>
<td>14</td>
</tr>
</tbody></table>
<h3 id="9-6-1-Integrating-Caches-and-VM"><a href="#9-6-1-Integrating-Caches-and-VM" class="headerlink" title="9.6.1 Integrating Caches and VM"></a>9.6.1 Integrating Caches and VM</h3><p><em>In any system that uses both virtual memory and SRAM caches, there is the issue of <strong>whether to use virtual or physical addresses to access the SRAM cache.</strong></em></p>
<p>Most systems opt for physical addressing</p>
<ul>
<li> It is straightforward for multiple processes to have blocks in the cache at the same time and to share blocks from the same virtual pages</li>
<li>The cache does not have to deal with protection issues, because access rights are checked as part of the address translation process.</li>
</ul>
<p><img src="/2021/10/05/CSAPP/Ch9/cachePA.png" alt="cache with physical addressing"></p>
<h3 id="9-6-2-Speeding-Up-Address-Translation-with-a-TLB"><a href="#9-6-2-Speeding-Up-Address-Translation-with-a-TLB" class="headerlink" title="9.6.2 Speeding Up Address Translation with a TLB"></a>9.6.2 Speeding Up Address Translation with a TLB</h3><p><em>Many systems try to eliminate even the cost of finding PTE in level-1 cache by including a small cache of PTEs in the MMU called a translation lookaside buffer (TLB).</em></p>
<ul>
<li>A TLB is a small, virtually addressed cache where each line holds a block consisting of a single PTE.</li>
<li>A TLB usually has a high degree of associativity</li>
</ul>
<p><img src="/2021/10/05/CSAPP/Ch9/tlb.png" alt="Translation lookaside buffer"></p>
<h4 id="TLB-Operation"><a href="#TLB-Operation" class="headerlink" title="TLB Operation"></a>TLB Operation</h4><p><img src="/2021/10/05/CSAPP/Ch9/tlboperation.png" alt="TLB operations"></p>
<h3 id="9-6-3-Multi-Level-Page-Tables"><a href="#9-6-3-Multi-Level-Page-Tables" class="headerlink" title="9.6.3 Multi-Level Page Tables"></a>9.6.3 Multi-Level Page Tables</h3><p><em>If we only use a single page table to do the translation, we will have a very large page table resident in memory</em></p>
<p><em>The common approach for compacting the page table is to use a hierarchy of page tables instead</em></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Just like two star pointer, it is a page table to page table</span></span><br><span class="line"><span class="comment">//PageTable can also be view as a page</span></span><br><span class="line">PageTable* level1 [N];</span><br></pre></td></tr></table></figure>


<p><img src="/2021/10/05/CSAPP/Ch9/multPT.png" alt="multiple level cache"></p>
<p>Why multiple level tables save space ? </p>
<ul>
<li>level 2(or lower levels) are generated dynamically, they only exist when they are needed).</li>
<li><code>sizeof(PageTable*) &lt; sizeof(PageTable)</code></li>
</ul>
<h3 id="9-6-4-Putting-It-Together-End-to-End-Address-Translation"><a href="#9-6-4-Putting-It-Together-End-to-End-Address-Translation" class="headerlink" title="9.6.4 Putting It Together: End-to-End Address Translation"></a>9.6.4 Putting It Together: End-to-End Address Translation</h3><h2 id="9-7-Case-Study-The-Intel-Core-i7-Linux-Memory-System"><a href="#9-7-Case-Study-The-Intel-Core-i7-Linux-Memory-System" class="headerlink" title="9.7 Case Study: The Intel Core i7/Linux Memory System"></a>9.7 Case Study: The Intel Core i7/Linux Memory System</h2><p><img src="/2021/10/05/CSAPP/Ch9/addrtrans.png" alt="address translation on real machine"></p>
<h3 id="9-7-1-Core-i7-Address-Translation"><a href="#9-7-1-Core-i7-Address-Translation" class="headerlink" title="9.7.1 Core i7 Address Translation"></a>9.7.1 Core i7 Address Translation</h3><p><img src="/2021/10/05/CSAPP/Ch9/pagetable.png" alt="page table entry"></p>
<p><img src="/2021/10/05/CSAPP/Ch9/level4addr.png" alt="level 4 page table entry"></p>
<h3 id="9-7-2-Linux-Virtual-Memory-System"><a href="#9-7-2-Linux-Virtual-Memory-System" class="headerlink" title="9.7.2 Linux Virtual Memory System"></a>9.7.2 Linux Virtual Memory System</h3><p><img src="/2021/10/05/CSAPP/Ch9/memspace.png" alt="Virtual Memory Space"></p>
<p>Each process shares the kernel’s code and global data structures.</p>
<h4 id="Linux-Virtual-Memory-Areas"><a href="#Linux-Virtual-Memory-Areas" class="headerlink" title="Linux Virtual Memory Areas"></a>Linux Virtual Memory Areas</h4><p><em>Linux organizes the virtual memory as a collection of <strong>areas</strong> (also called segments).</em></p>
<ul>
<li>An area is a contiguous chunk of existing (allocated) virtual memory whose pages are related in some way</li>
<li> the code segment, data segment, heap, shared library segment, and user stack are all distinct areas.</li>
<li>The kernel maintains a <strong>distinct task structure</strong> (<code>task_ struct</code> in the source code) for each process in the system.<ul>
<li>The elements of the task structure either contain or point to all of the information that the kernel needs to run the process (e.g., the PID, pointer to the user stack, name of the executable object file, and program counter)</li>
</ul>
</li>
</ul>
<p><img src="/2021/10/05/CSAPP/Ch9/taskstruct.png" alt="task structure"></p>
<ul>
<li>One of the entries in the task structure points to an <code>mm_struct</code> that characterizes the current state of the virtual memory.<ul>
<li><code>pgd</code>, which points to <strong>the base of the level 1 table</strong> (the page global directory)</li>
<li><code>mmap</code>, which points to a list of <code>vm_area_structs</code> (area structs), each of which characterizes <strong>an area of the current virtual address space</strong></li>
</ul>
</li>
</ul>
<p><code>fvm_start</code> Points to the beginning of the area. </p>
<p><code>vm_end</code>. Points to the end of the area.</p>
<p><code>vm_prot</code>. Describes the read/write permissions for all of the pages contained in the area. </p>
<p><code>vm_flags</code>. Describes (among other things) whether the pages in the area are shared with other processes or private to this process. </p>
<p><code>vm_next</code>. Points to the next area struct in the list.</p>
<h4 id="Linux-Page-Fault-Exception-Handling"><a href="#Linux-Page-Fault-Exception-Handling" class="headerlink" title="Linux Page Fault Exception Handling"></a>Linux Page Fault Exception Handling</h4><p><img src="/2021/10/05/CSAPP/Ch9/pagefaulthandler.png" alt="page fault handling"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isValid</span>(<span class="params">trigger_address</span>):</span></span><br><span class="line">    flag = <span class="literal">False</span></span><br><span class="line">    <span class="comment"># So in practice, Linux superimposes a tree on the list, using some fields that we have not shown, and performs the search on this tree</span></span><br><span class="line">    <span class="keyword">for</span> AreaStruct <span class="keyword">in</span> AreaStructList:</span><br><span class="line">        <span class="keyword">if</span> AreaStruct.vm_start &lt;= trigger_address &lt;= AreaStruct.vm_end:</span><br><span class="line">            flag = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> flag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isLegal</span>(<span class="params">trigger_address</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Does the process have permission to read, write, or execute the pages in this area? For example, was the page fault the result of a store instruction trying to write to a readonly page in the code segment?&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PageFaultHandler</span>(<span class="params">trigger_address</span>):</span></span><br><span class="line">    <span class="keyword">if</span> isValid(trigger_address) == <span class="literal">False</span>:</span><br><span class="line">        <span class="keyword">raise</span> SegmentationFault</span><br><span class="line">        <span class="comment"># terminates the process</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> isLegal(trigger_address) == <span class="literal">False</span>:</span><br><span class="line">        <span class="keyword">raise</span> ProtectionException</span><br><span class="line">        <span class="comment"># terminates the process</span></span><br><span class="line">     </span><br><span class="line">     <span class="string">&#x27;&#x27;&#x27;selecting a victim page, swapping out the victim page if it is dirty, swapping in the new page,and updating the page table.&#x27;&#x27;&#x27;</span></span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">   </span><br><span class="line"><span class="comment"># When the page fault handler returns, the CPU restarts the faulting instruction, which sends A to the MMU again.</span></span><br></pre></td></tr></table></figure>
<h2 id="9-8-Memory-Mapping"><a href="#9-8-Memory-Mapping" class="headerlink" title="9.8 Memory Mapping"></a>9.8 Memory Mapping</h2><p><em>Linux initializes the contents of a virtual memory area by <strong>associating it with an object on disk</strong>, a process known as <strong>memory mapping</strong></em></p>
<p>Areas can be mapped to one of two types of objects:</p>
<ul>
<li>Regular file in the Linux file system<ul>
<li>The file section is divided into page-size pieces, with each piece containing the initial contents of a virtual page. </li>
<li>Because of demand paging, none of these virtual pages is actually swapped into physical memory until the CPU first touches the page</li>
<li>If the area is larger than the file section, then the area is padded with zeros.</li>
</ul>
</li>
<li>Anonymous file<ul>
<li>An area can also be mapped to an anonymous file, created by the kernel, that <strong>contains all binary zeros</strong>.</li>
<li>The first time the CPU touches a virtual page in such an area, the kernel finds an appropriate victim page in physical memory, swaps out the victim page if it is dirty, <strong>overwrites the victim page with binary zeros</strong>, and updates the page table to mark the page as resident.</li>
<li>Notice that <strong>no data are actually transferred between disk and memory</strong> if no dirty page</li>
</ul>
</li>
</ul>
<p>In either case, once a virtual page is initialized, it is swapped back and forth between a special <strong>swap file</strong>(aka <strong>swap space</strong> or the <strong>swap area</strong>) maintained by the kernel.</p>
<p><strong><em>At any point in time, the swap space bounds the total amount of virtual pages that can be allocated by the currently running processes.</em></strong></p>
<h3 id="9-8-1-Shared-Objects-Revisited"><a href="#9-8-1-Shared-Objects-Revisited" class="headerlink" title="9.8.1 Shared Objects Revisited"></a>9.8.1 Shared Objects Revisited</h3><p><em>If the virtual memory system could be integrated into the conventional file system, then it could provide a simple and efficient way to load programs and data into memory</em></p>
<p>An object can be mapped into an area of virtual memory as either a <strong>shared object</strong> or a <strong>private object</strong></p>
<h5 id="Shared"><a href="#Shared" class="headerlink" title="Shared"></a>Shared</h5><p><img src="/2021/10/05/CSAPP/Ch9/sharedobj.png" alt="shared object"></p>
<ul>
<li>Only a single copy of the shared object needs to be stored in physical memory, even though the object is mapped into multiple shared areas.</li>
</ul>
<h5 id="Private"><a href="#Private" class="headerlink" title="Private"></a>Private</h5><p><img src="/2021/10/05/CSAPP/Ch9/privateobj.png" alt="private object"></p>
<ul>
<li>Private objects are mapped into virtual memory using a clever technique known as <strong>copy-on-write</strong></li>
<li> A private object begins life in exactly the same way as a shared object, <strong>with only one copy of the private object stored in physical memory</strong></li>
<li>For each process that maps the private object, the page table entries for the corresponding private area are flagged as <strong>read-only</strong>, and the area struct is flagged as <strong>private copy-on-write</strong>.</li>
<li>As soon as a process attempts to write to some page in the private area, the write <strong>triggers a protection fault</strong>.</li>
<li>When the fault handler notices that the protection exception was caused by the process trying to write to a page in a private copy-on-write area, <strong>it creates a new copy of the page in physical memory, updates the page table entry to point to the new copy, and then restores write permissions to the page</strong></li>
<li>When the fault handler returns, the CPU re-executes the write, which now <strong>proceeds normally on the newly created page</strong>.</li>
<li>By <strong>deferring the copying of the pages in private objects until the last possible moment</strong>, copy-on-write makes the most efficient use of scarce physical memory</li>
</ul>
<h3 id="9-8-2-The-fork-Function-Revisited"><a href="#9-8-2-The-fork-Function-Revisited" class="headerlink" title="9.8.2 The fork Function Revisited"></a>9.8.2 The <code>fork</code> Function Revisited</h3><p>When the <code>fork</code> function is called by the current process :</p>
<ul>
<li>The kernel creates <strong>various data structures for the new process</strong> and assigns it a unique PID.</li>
<li>creates exact copies of the current process’s <code>mm_struct</code>, <code>area structs</code>, and <code>page tables</code>.(Now the memory copy of the old process has already been created!!!)</li>
<li>It flags each page in both processes as <strong>read-only</strong>, and flags each area struct in both processes as <strong>private copy-on-write</strong>.</li>
<li>When the <code>fork</code> returns in the new process, <strong>the new process now has an exact copy of the virtual memory as it existed</strong> when the <code>fork</code> was called</li>
<li>When either of the processes performs any subsequent writes, the copy-on-write mechanism creates new pages</li>
</ul>
<h3 id="9-8-3-The-execve-Function-Revisited"><a href="#9-8-3-The-execve-Function-Revisited" class="headerlink" title="9.8.3 The execve Function Revisited"></a>9.8.3 The <code>execve</code> Function Revisited</h3><p>When <code>execve(&quot;a.out&quot;, NULL, NULL);</code>, the following steps are performed</p>
<p><img src="/2021/10/05/CSAPP/Ch9/override.png" alt="override memory space"></p>
<ul>
<li><strong>Delete existing user areas</strong>. Delete the existing area structs in the user portion of the current process’s virtual address</li>
<li><strong>Map private areas.</strong> Create new area structs for the code, data, bss, and stack areas of the new program. All of these new areas are private copy-on-write. The code and data areas are mapped to the .text and .data sections of the a.out file. The bss area is demand-zero, mapped to an anonymous file whose size is contained in a.out. The stack and heap area are also demand-zero, initially of zero length. </li>
<li><strong>Map shared areas.</strong></li>
<li><strong>Set the program counter (PC)</strong>. The last thing that execve does is to set the program counter in the current process’s context to point to the entry point in the code area.</li>
</ul>
<h3 id="9-8-4-User-Level-Memory-Mapping-with-the-mmap-Function"><a href="#9-8-4-User-Level-Memory-Mapping-with-the-mmap-Function" class="headerlink" title="9.8.4 User-Level Memory Mapping with the mmap Function"></a>9.8.4 User-Level Memory Mapping with the <code>mmap </code>Function</h3><p><em>Linux processes can use the <code>mmap</code> function to <strong>create new areas of virtual memory and to map objects into these areas</strong>.</em></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">mmap</span><span class="params">(<span class="keyword">void</span> *start, <span class="keyword">size_t</span> length, <span class="keyword">int</span> prot, <span class="keyword">int</span> flags,<span class="keyword">int</span> fd, <span class="keyword">off_t</span> offset)</span></span>;</span><br><span class="line"><span class="comment">//Returns: pointer to mapped area if OK, MAP_FAILED (−1) on error</span></span><br></pre></td></tr></table></figure>
<p><img src="/2021/10/05/CSAPP/Ch9/mmp.png" alt="memory map"></p>
<ul>
<li>The <code>mmap</code> function asks the kernel to <strong>create a new virtual memory area</strong>, preferably one that starts at address <code>start</code>, and to <strong>map a contiguous chunk of the object specified by file descriptor <code>fd</code> to the new area</strong></li>
<li>The contiguous object chunk has a size of <code>length</code> bytes and starts at an <code>offset</code> of offset bytes from the beginning of the file. </li>
<li>The start address is merely a hint(the final decision is made by kernal), and is usually specified as <code>NULL</code>.</li>
<li>The <code>prot</code> argument contains bits that describe the <strong>access permissions</strong> of the newly mapped virtual memory area</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;PROT_EXEC : <span class="string">&quot;Pages in the area consist of instructions that may be executed by the CPU.&quot;</span>,</span><br><span class="line">PROT_READ : <span class="string">&quot;Pages in the area may be read.&quot;</span>,</span><br><span class="line">PROT_WRITE : <span class="string">&quot;Pages in the area may be written&quot;</span>,</span><br><span class="line">PROT_NONE :<span class="string">&quot;Pages in the area cannot be accessed.&quot;</span>&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>The <code>flags</code> argument consists of bits that <strong>describe the type of the mapped object.</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     MAP_ANON : <span class="string">&quot;the backing store is an anonymous object and the corresponding virtual pages are demand-zero&quot;</span>,</span><br><span class="line">     MAP_PRIVATE : <span class="string">&quot;A private copy-on-write object&quot;</span>,</span><br><span class="line">     MAP_SHARED : <span class="string">&quot;A shared object&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<p>The <code>munmap</code> function deletes regions of virtual memory:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">munmap</span><span class="params">(<span class="keyword">void</span> *start, <span class="keyword">size_t</span> length)</span></span>;</span><br><span class="line"><span class="comment">//Returns: 0 if OK, −1 on error</span></span><br></pre></td></tr></table></figure>
<p>The <code>munmap</code> function deletes the area starting at virtual address <code>start</code> and consisting of the next <code>length</code> bytes. Subsequent references to the deleted region result in segmentation faults.</p>
<h4 id="Practice-Problem-9-5"><a href="#Practice-Problem-9-5" class="headerlink" title="Practice Problem 9.5"></a>Practice Problem 9.5</h4><blockquote>
<p>Write a C program <code>mmapcopy.c</code> that uses <code>mmap</code> to copy an arbitrary-size disk file to<code> stdout</code>. The name of the input file should be passed as a command-line argument.</p>
</blockquote>
<h4 id="My-solution"><a href="#My-solution" class="headerlink" title="My solution :"></a>My solution :</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//No error checking below</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc , <span class="keyword">char</span> * argv [])</span></span>&#123;</span><br><span class="line">   <span class="keyword">int</span> fd = open(argv[<span class="number">1</span>], O_RDONLY);</span><br><span class="line">   <span class="keyword">size_t</span> len = lseek(fd, <span class="number">0</span>, SEEK_END);</span><br><span class="line">   <span class="keyword">char</span> * res = mmap(<span class="literal">NULL</span> , len, PROT_READ, MAP_PRIVATE, fd , <span class="number">0</span>);</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span> , res);</span><br><span class="line">   close(fd);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Modified-solution-on-the-book"><a href="#Modified-solution-on-the-book" class="headerlink" title="Modified solution on the book:"></a>Modified solution on the book:</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//No error checking below</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc , <span class="keyword">char</span> * argv [])</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> fd ; </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">stat</span> <span class="title">stat</span>;</span></span><br><span class="line">    fd = open(argv[<span class="number">1</span>], O_RDONLY , <span class="number">0</span> );</span><br><span class="line">    fstat(fd, &amp;stat);</span><br><span class="line">    <span class="keyword">char</span> * bufp = mmap(<span class="literal">NULL</span>, stat.st_size, PROT_READ, MAP_PRIVATE, fd, <span class="number">0</span>);</span><br><span class="line">    write(<span class="number">1</span>, bufp, stat.st_size);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="9-9-Dynamic-Memory-Allocation"><a href="#9-9-Dynamic-Memory-Allocation" class="headerlink" title="9.9 Dynamic Memory Allocation"></a>9.9 Dynamic Memory Allocation</h2><p><em>For each process, the kernel maintains a variable <code>brk</code> (pronounced “break”) that <strong>points to the top of the heap</strong></em></p>
<ul>
<li><p>An allocator maintains the heap as a collection of <strong>various-size blocks</strong>.</p>
</li>
<li><p>Allocators come in two basic styles. Both styles require the application to explicitly allocate blocks. They differ about <strong>which entity is responsible for freeing allocated blocks.</strong></p>
<ul>
<li><p>Explicit allocators : require the application to explicitly free any allocated blocks.(<code>malloc</code> and <code>free</code>)</p>
</li>
<li><p>Implicit allocators : require the allocator to detect when an allocated block is no longer being used by the program and then free the block.(<strong>garbage collectors</strong>)</p>
</li>
</ul>
</li>
<li><p> memory allocation is a general idea that arises in a variety of contexts(Not only for manage heap memory)</p>
</li>
</ul>
<h3 id="9-9-1-The-malloc-and-free-Functions"><a href="#9-9-1-The-malloc-and-free-Functions" class="headerlink" title="9.9.1 The malloc and free Functions"></a>9.9.1 The malloc and free Functions</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">malloc</span><span class="params">(<span class="keyword">size_t</span> size)</span></span>;</span><br><span class="line"><span class="comment">//Returns: pointer to allocated block if OK, NULL on error</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>The <code>malloc</code> function returns a pointer to a block of memory of <strong>at least</strong> <code>size</code> bytes that is <strong>suitably aligned</strong></p>
</li>
<li><p><code>malloc</code> <strong>does not initialize the memory</strong> it returns</p>
<ul>
<li>Applications that want initialized dynamic memory can use <code>calloc</code>, a thin wrapper around the <code>malloc</code></li>
<li>Applications that want to change the size of a previously allocated block can use the <code>realloc</code> function.</li>
</ul>
</li>
</ul>
<hr>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">sbrk</span><span class="params">(<span class="keyword">intptr_t</span> incr)</span></span>;</span><br><span class="line"><span class="comment">//Returns: old brk pointer on success, −1 on error</span></span><br></pre></td></tr></table></figure>
<p>The <code>sbrk</code> function grows or shrinks the heap by <strong>adding <code>incr</code> to the kernel’s brk pointer</strong></p>
<ul>
<li> Calling <code>sbrk</code> with a <strong>negative <code>incr</code></strong> is legal but tricky because the return value (the old value of brk) points to abs(incr) bytes past the new top of the heap.</li>
</ul>
<hr>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">(<span class="keyword">void</span> *ptr)</span></span>;</span><br></pre></td></tr></table></figure>
<p>The <code>ptr</code> argument <strong>must point to the beginning of an allocated block that was obtained from</strong> <code>malloc</code>, <code>calloc</code>, or <code>realloc</code>. If not, then the behavior of free is <strong>undefined</strong></p>
<hr>
<p><img src="/2021/10/05/CSAPP/Ch9/mallocexample.png" alt="Example"></p>
<h3 id="9-9-2-Why-Dynamic-Memory-Allocation"><a href="#9-9-2-Why-Dynamic-Memory-Allocation" class="headerlink" title="9.9.2 Why Dynamic Memory Allocation?"></a>9.9.2 Why Dynamic Memory Allocation?</h3><p><em>The most important reason that programs use dynamic memory allocation is that often <strong>they do not know the sizes of certain data structures until the program actually runs</strong></em></p>
<h3 id="9-9-3-Allocator-Requirements-and-Goals"><a href="#9-9-3-Allocator-Requirements-and-Goals" class="headerlink" title="9.9.3 Allocator Requirements and Goals"></a>9.9.3 Allocator Requirements and Goals</h3><h4 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints"></a>Constraints</h4><p><em>Explicit allocators must <strong>operate within</strong> some rather stringent <strong>constraints</strong></em></p>
<ul>
<li>Handling arbitrary request sequences<ul>
<li>An application can make an arbitrary sequence of allocate and free requests</li>
<li> the allocator cannot make any assumptions about the ordering of allocate and free requests.</li>
</ul>
</li>
<li>Making immediate responses to requests<ul>
<li> the allocator is not allowed to reorder or buffer requests in order to improve performance.</li>
</ul>
</li>
<li>Using only the heap</li>
<li>Aligning blocks (alignment requirement). <ul>
<li>The allocator must align blocks in such a way that they can <strong>hold any type of data object</strong></li>
</ul>
</li>
<li>Not modifying allocated blocks.<ul>
<li>Allocators can only manipulate or change free blocks. </li>
<li>they are not allowed to modify or move blocks once they are allocated</li>
<li> techniques such as compaction of allocated blocks are not permitted.</li>
</ul>
</li>
</ul>
<h4 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h4><ul>
<li>Maximizing throughput.</li>
<li>Maximizing memory utilization</li>
</ul>
<h3 id="9-9-4-Fragmentation"><a href="#9-9-4-Fragmentation" class="headerlink" title="9.9.4 Fragmentation"></a>9.9.4 Fragmentation</h3><p><em>unused memory is not available to satisfy allocate requests.</em></p>
<p>There are two forms of fragmentation: </p>
<h4 id="Internal-fragmentation"><a href="#Internal-fragmentation" class="headerlink" title="Internal fragmentation"></a>Internal fragmentation</h4><ul>
<li>Internal fragmentation occurs when an allocated block size is larger than the required size</li>
<li>It is simply the sum of the differences between the sizes of the allocated blocks and their requirements</li>
<li>Thus, at any point in time, the amount of internal fragmentation depends only on the pattern of previous requests and the allocator implementation.</li>
</ul>
<h4 id="External-fragmentation"><a href="#External-fragmentation" class="headerlink" title="External fragmentation"></a>External fragmentation</h4><ul>
<li><p>External fragmentation occurs when there is enough aggregate free memory to satisfy an allocate request, but no single free block is large enough to handle the request.</p>
</li>
<li><p>Figure 9.34 (e)</p>
</li>
<li><p>External fragmentation is much more difficult to quantify than internal fragmentation because it depends not only on the pattern of previous requests and the allocator implementation but also on the pattern of future requests</p>
</li>
</ul>
<h3 id="9-9-5-Implementation-Issues"><a href="#9-9-5-Implementation-Issues" class="headerlink" title="9.9.5 Implementation Issues"></a>9.9.5 Implementation Issues</h3><p><em>A practical allocator that <strong>strikes a balance between throughput and utilization</strong> must consider the following issues:</em></p>
<ul>
<li>Free block organization. How do we keep track of free blocks?</li>
<li>Placement. How do we choose an appropriate free block in which to place a newly allocated block?</li>
<li>Splitting. After we place a newly allocated block in some free block, what do we do with the remainder of the free block?</li>
<li>Coalescing. What do we do with a block that has just been freed?</li>
</ul>
<h3 id="9-9-6-Implicit-Free-Lists"><a href="#9-9-6-Implicit-Free-Lists" class="headerlink" title="9.9.6 Implicit Free Lists"></a>9.9.6 Implicit Free Lists</h3><p><em>Any practical allocator needs some <strong>data structure</strong> that allows it to <strong>distinguish block boundaries</strong> and to <strong>distinguish between allocated and free blocks</strong>.</em></p>
<ul>
<li>Most allocators em<strong>bed this information in the blocks themselves</strong>. </li>
</ul>
<p><img src="/2021/10/05/CSAPP/Ch9/heapblock.png" alt="block"></p>
<ul>
<li>A significant disadvantage is that the cost of any operation that requires a search of the free list, such as placing allocated blocks, will be linear in the total number of allocated and free blocks in the heap.</li>
<li>Notice that we need some kind of specially marked end block(size of 0, allocated)</li>
</ul>
<p><img src="/2021/10/05/CSAPP/Ch9/simplelistorg.png" alt="simple list organziation"></p>
<ul>
<li><code>start of the heap</code> might no be aligned, so we need some <code>unused</code> block at the beginning to do the alignment</li>
</ul>
<h4 id="Practice-Problem-9-6"><a href="#Practice-Problem-9-6" class="headerlink" title="Practice Problem 9.6"></a>Practice Problem 9.6</h4><blockquote>
<p>Determine the block sizes and header values that would result from the following sequence of <code>malloc</code> requests. </p>
<p>Assumptions: (1) The allocator maintains double-word alignment and uses an implicit free list with the block format from Figure 9.35. (2) Block sizes are rounded up to the nearest multiple of 8 bytes.</p>
<table>
<thead>
<tr>
<th>Request</th>
<th>Block size (decimal bytes)</th>
<th>Block header (hex)</th>
</tr>
</thead>
<tbody><tr>
<td>malloc(2)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>malloc(9)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>malloc(15)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>malloc(20)</td>
<td></td>
<td></td>
</tr>
</tbody></table>
</blockquote>
<h4 id="My-solution-white-check-mark-2"><a href="#My-solution-white-check-mark-2" class="headerlink" title="My solution : :white_check_mark:"></a>My solution : :white_check_mark:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;0x&#123;:08x&#125;&#x27;</span>.<span class="built_in">format</span>(blocksize | <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>Request</th>
<th>Block size (decimal bytes)</th>
<th>Block header (hex)</th>
</tr>
</thead>
<tbody><tr>
<td>malloc(2)</td>
<td>8</td>
<td>0x00000009</td>
</tr>
<tr>
<td>malloc(9)</td>
<td>16</td>
<td>0x00000011</td>
</tr>
<tr>
<td>malloc(15)</td>
<td>24</td>
<td>0x00000019</td>
</tr>
<tr>
<td>malloc(20)</td>
<td>24</td>
<td>0x00000019</td>
</tr>
</tbody></table>
<h3 id="9-9-7-Placing-Allocated-Blocks"><a href="#9-9-7-Placing-Allocated-Blocks" class="headerlink" title="9.9.7 Placing Allocated Blocks"></a>9.9.7 Placing Allocated Blocks</h3><p>When an application requests a block of k bytes, the allocator <strong>searches the free list for a free block that is large enough to hold the requested block</strong>. The manner in which the allocator performs this search is determined by the placement policy. Some common policies are first fit, next fit, and best fit.</p>
<ul>
<li>First fit searches the free list from the beginning and chooses the first free block that fits</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">p = start ; <span class="comment">//start from the beginning</span></span><br><span class="line"><span class="keyword">while</span>( (p&lt;end) <span class="comment">//not pass the end</span></span><br><span class="line">      &amp;&amp; ( (*p &amp; <span class="number">1</span>) || (*p &amp; <span class="number">-2</span>) )) <span class="comment">// already allocated or size is too small</span></span><br><span class="line">&#123;</span><br><span class="line">    p = p + (*p &amp; <span class="number">-2</span>) ; <span class="comment">//go to next block via size</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Next fit is similar to first fit, but instead of starting each search at the beginning of the list, it starts each search where the previous search left off.</li>
<li>Best fit examines every free block and chooses the free block with the smallest size that fits</li>
</ul>
<h3 id="9-9-8-Splitting-Free-Blocks"><a href="#9-9-8-Splitting-Free-Blocks" class="headerlink" title="9.9.8 Splitting Free Blocks"></a>9.9.8 Splitting Free Blocks</h3><h3 id="9-9-9-Getting-Additional-Heap-Memory"><a href="#9-9-9-Getting-Additional-Heap-Memory" class="headerlink" title="9.9.9 Getting Additional Heap Memory"></a>9.9.9 Getting Additional Heap Memory</h3><p><em>use <code>sbrk</code> to ask more space from the kernal</em></p>
<h3 id="9-9-10-Coalescing-Free-Blocks"><a href="#9-9-10-Coalescing-Free-Blocks" class="headerlink" title="9.9.10 Coalescing Free Blocks"></a>9.9.10 Coalescing Free Blocks</h3><p><em>To combat false fragmentation, any practical allocator must merge adjacent free blocks in a process known as coalescing.</em></p>
<p>This raises an important policy decision about when to perform coalescing.</p>
<h3 id="9-9-11-Coalescing-with-Boundary-Tags"><a href="#9-9-11-Coalescing-with-Boundary-Tags" class="headerlink" title="9.9.11 Coalescing with Boundary Tags"></a>9.9.11 Coalescing with Boundary Tags</h3><p><img src="/2021/10/05/CSAPP/Ch9/boundarytag.png" alt="boundary tag"></p>
<p>(If we were to <strong>store the allocated/free bit of the previous block in one of the excess loworder bits of the current block</strong>, then allocated blocks would not need footers, and we could use that extra space for payload. Note, however, that free blocks would still need footers)</p>
<p>(When coalescing free blocks, we always update the <strong>first free block’s</strong> size)</p>
<p><img src="/2021/10/05/CSAPP/Ch9/coalesce.png" alt="coalesce"></p>
<h3 id="9-9-12-Putting-It-Together-Implementing-a-Simple-Allocator"><a href="#9-9-12-Putting-It-Together-Implementing-a-Simple-Allocator" class="headerlink" title="9.9.12 Putting It Together: Implementing a Simple Allocator"></a>9.9.12 Putting It Together: Implementing a Simple Allocator</h3><p>Implicit list strategy is not used in <code>malloc</code> and <code>free</code> for the sake of linear time complexity.</p>
<h3 id="9-9-13-Explicit-Free-Lists"><a href="#9-9-13-Explicit-Free-Lists" class="headerlink" title="9.9.13 Explicit Free Lists"></a>9.9.13 Explicit Free Lists</h3><p><em>Since by definition the body of a free block is not needed by the program, the pointers that implement the data structure can be stored <strong>within the bodies of the free blocks</strong>.</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/explicitexample.png" alt="explicit list"></p>
<ul>
<li>Using a doubly linked list instead of an implicit free list reduces the first-fit allocation time from linear in the total number of blocks to linear in the number of free blocks. </li>
<li>A disadvantage of explicit lists in general is that free blocks must be large enough to contain all of the necessary pointers, as well as the header and possibly a footer. This results in a larger minimum block size and increases the potential for internal fragmentation.</li>
</ul>
<h3 id="9-9-14-Segregated-Free-Lists"><a href="#9-9-14-Segregated-Free-Lists" class="headerlink" title="9.9.14 Segregated Free Lists"></a>9.9.14 Segregated Free Lists</h3><p><em>A popular approach for reducing the allocation time, known generally as <strong>segregated storage</strong>, is to maintain multiple free lists, where <strong>each list holds blocks that are roughly the same size.</strong></em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/segregatelist.png" alt="segregate lists"></p>
<p>For example</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># partition the block sizes by powers of 2</span></span><br><span class="line">&#123;<span class="number">1</span>&#125;, &#123;<span class="number">2</span>&#125;, &#123;<span class="number">3</span>, <span class="number">4</span>&#125;, &#123;<span class="number">5</span> – <span class="number">8</span>&#125;, ... , &#123;<span class="number">1025</span> – <span class="number">2048</span>&#125;, &#123;<span class="number">2049</span> – <span class="number">4096</span>&#125;, &#123;<span class="number">4097</span> – ∞&#125;</span><br><span class="line"><span class="comment"># Or we might assign small blocks to their own size classes and partition large blocks by powers of 2</span></span><br><span class="line">&#123;<span class="number">1</span>&#125;, &#123;<span class="number">2</span>&#125;, &#123;<span class="number">3</span>&#125;, ... , &#123;<span class="number">1023</span>&#125;, &#123;<span class="number">1024</span>&#125;, &#123;<span class="number">1025</span>–<span class="number">2048</span>&#125;, &#123;<span class="number">2049</span>–<span class="number">4096</span>&#125;, &#123;<span class="number">4097</span>–∞&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>The allocator maintains an array of free lists, with one free list per size class, ordered by increasing size</li>
<li>When the allocator needs a block of size n, it searches the appropriate free list. If it cannot find a block that fits, it searches the next list, and so on.</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FreeBlock* lists[N];</span><br><span class="line"><span class="comment">//malloc(size)</span></span><br><span class="line"><span class="keyword">return</span> search(lists[index] , size);</span><br></pre></td></tr></table></figure>
<h4 id="Simple-Segregated-Storage"><a href="#Simple-Segregated-Storage" class="headerlink" title="Simple Segregated Storage"></a>Simple Segregated Storage</h4><p><em>With simple segregated storage, the free list for each size class <strong>contains same-size blocks, each the size of the largest element of the size class</strong>.</em></p>
<p>(For example, if some size class is defined as {17–32}, then the free list for that class consists entirely of blocks of size 32)</p>
<h4 id="Segregated-Fits"><a href="#Segregated-Fits" class="headerlink" title="Segregated Fits"></a>Segregated Fits</h4><p><em>The segregated fits approach is a popular choice with production-quality allocators such as the GNU <code>malloc</code> package provided in the C standard library because it is both fast and memory efficient.</em></p>
<ul>
<li>With this approach, the allocator maintains an array of free lists. Each free list is associated with a size class and is organized as some kind of explicit or implicit list. Each list contains potentially different-size blocks whose sizes are members of the size class</li>
<li>To allocate a block, we determine the size class of the request and do a firstfit search of the appropriate free list for a block that fits.<ul>
<li>If we find one, then we (optionally) split it and insert the fragment in the appropriate free list. </li>
<li>If we cannot find a block that fits, then we search the free list for the next larger size class.</li>
<li>If none of the free lists yields a block that fits, then we request additional heap memory from the operating system, allocate the block out of this new heap memory, and place the remainder in the appropriate size class</li>
</ul>
</li>
<li>To free a block, we coalesce and place the result on the appropriate free list.</li>
</ul>
<h4 id="Buddy-Systems"><a href="#Buddy-Systems" class="headerlink" title="Buddy Systems"></a>Buddy Systems</h4><p><em>A buddy system is a special case of segregated fits where each size class is a power of 2.</em></p>
<ul>
<li>The major advantage of a buddy system allocator is its fast searching and coalescing.</li>
<li>The major disadvantage is that the power-of-2 requirement on the block size can cause significant internal fragmentation.</li>
</ul>
<h2 id="9-10-Garbage-Collection"><a href="#9-10-Garbage-Collection" class="headerlink" title="9.10 Garbage Collection"></a>9.10 Garbage Collection</h2><p><em>A garbage collector is a dynamic storage allocator that automatically frees allocated blocks that are no longer needed by the program</em></p>
<h3 id="9-10-1-Garbage-Collector-Basics"><a href="#9-10-1-Garbage-Collector-Basics" class="headerlink" title="9.10.1 Garbage Collector Basics"></a>9.10.1 Garbage Collector Basics</h3><p><strong><em>A garbage collector views memory as a <code>directed reachability graph</code> of the form shown in Figure 9.49</em></strong></p>
<p><img src="/2021/10/05/CSAPP/Ch9/graph.png" alt="directed reachability graph"></p>
<ul>
<li>The nodes of the graph are partitioned into a set of root nodes and a set of heap nodes<ul>
<li>Each heap node corresponds to an allocated block in the heap. </li>
<li>A directed edge<code> p → q</code> means that some location in block p points to some location in block q</li>
<li>Root nodes correspond to locations not in the heap that contain pointers into the heap. These locations can be registers, variables on the stack, or global variables in the read/write data area of virtual memory</li>
</ul>
</li>
<li>We say that a node p is reachable if there exists a directed path from any root node to p</li>
<li>The role of a garbage collector is to <strong>maintain some representation of the reachability graph</strong> and <strong>periodically reclaim the unreachable nodes</strong> by freeing them and returning them to the free list.</li>
</ul>
<p>Collectors can provide their service on demand, or they can run as separate threads in parallel with the application, continuously updating the reachability graph and reclaiming garbage.</p>
<h3 id="9-10-2-Mark-amp-Sweep-Garbage-Collectors"><a href="#9-10-2-Mark-amp-Sweep-Garbage-Collectors" class="headerlink" title="9.10.2 Mark&amp;Sweep Garbage Collectors"></a>9.10.2 Mark&amp;Sweep Garbage Collectors</h3><p><em>A Mark&amp;Sweep garbage collector consists of a <strong>mark phase, which marks all reachable and allocated descendants of the root nodes</strong>, followed by a <strong>sweep phase, which frees each unmarked allocated block</strong>.</em></p>
<p><img src="/2021/10/05/CSAPP/Ch9/marksweep.png" alt="mark sweep example"></p>
<h3 id="9-10-3-Conservative-Mark-amp-Sweep-for-C-Programs"><a href="#9-10-3-Conservative-Mark-amp-Sweep-for-C-Programs" class="headerlink" title="9.10.3 Conservative Mark&amp;Sweep for C Programs"></a>9.10.3 Conservative Mark&amp;Sweep for C Programs</h3><p><em>Since C does not tag memory locations with any type information(No way to determine if the data is a pointer or not), the algorithm have to be conservative.</em></p>
<h2 id="9-11-Common-Memory-Related-Bugs-in-C-Programs"><a href="#9-11-Common-Memory-Related-Bugs-in-C-Programs" class="headerlink" title="9.11 Common Memory-Related Bugs in C Programs"></a>9.11 Common Memory-Related Bugs in C Programs</h2><h3 id="9-11-1-Dereferencing-Bad-Pointers"><a href="#9-11-1-Dereferencing-Bad-Pointers" class="headerlink" title="9.11.1 Dereferencing Bad Pointers"></a>9.11.1 Dereferencing Bad Pointers</h3><h3 id="9-11-2-Reading-Uninitialized-Memory"><a href="#9-11-2-Reading-Uninitialized-Memory" class="headerlink" title="9.11.2 Reading Uninitialized Memory"></a>9.11.2 Reading Uninitialized Memory</h3><p><em>A common error is to assume that heap memory is initialized to zero</em></p>
<h3 id="9-11-3-Allowing-Stack-Buffer-Overflows"><a href="#9-11-3-Allowing-Stack-Buffer-Overflows" class="headerlink" title="9.11.3 Allowing Stack Buffer Overflows"></a>9.11.3 Allowing Stack Buffer Overflows</h3><h3 id="9-11-4-Assuming-That-Pointers-and-the-Objects-They-Point-to-Are-the-Same-Size"><a href="#9-11-4-Assuming-That-Pointers-and-the-Objects-They-Point-to-Are-the-Same-Size" class="headerlink" title="9.11.4 Assuming That Pointers and the Objects They Point to Are the Same Size"></a>9.11.4 Assuming That Pointers and the Objects They Point to Are the Same Size</h3><h3 id="9-11-5-Making-Off-by-One-Errors"><a href="#9-11-5-Making-Off-by-One-Errors" class="headerlink" title="9.11.5 Making Off-by-One Errors"></a>9.11.5 Making Off-by-One Errors</h3><h3 id="9-11-6-Referencing-a-Pointer-Instead-of-the-Object-It-Points-To"><a href="#9-11-6-Referencing-a-Pointer-Instead-of-the-Object-It-Points-To" class="headerlink" title="9.11.6 Referencing a Pointer Instead of the Object It Points To"></a>9.11.6 Referencing a Pointer Instead of the Object It Points To</h3><h3 id="9-11-7-Misunderstanding-Pointer-Arithmetic"><a href="#9-11-7-Misunderstanding-Pointer-Arithmetic" class="headerlink" title="9.11.7 Misunderstanding Pointer Arithmetic"></a>9.11.7 Misunderstanding Pointer Arithmetic</h3><h3 id="9-11-8-Referencing-Nonexistent-Variables"><a href="#9-11-8-Referencing-Nonexistent-Variables" class="headerlink" title="9.11.8 Referencing Nonexistent Variables"></a>9.11.8 Referencing Nonexistent Variables</h3><h3 id="9-11-9-Referencing-Data-in-Free-Heap-Blocks"><a href="#9-11-9-Referencing-Data-in-Free-Heap-Blocks" class="headerlink" title="9.11.9 Referencing Data in Free Heap Blocks"></a>9.11.9 Referencing Data in Free Heap Blocks</h3><h3 id="9-11-10-Introducing-Memory-Leaks"><a href="#9-11-10-Introducing-Memory-Leaks" class="headerlink" title="9.11.10 Introducing Memory Leaks"></a>9.11.10 Introducing Memory Leaks</h3><h2 id="9-12-Summary"><a href="#9-12-Summary" class="headerlink" title="9.12 Summary"></a>9.12 Summary</h2><p><img src="/2021/10/05/CSAPP/Ch9/dealwithbugs.png" alt="deal with bugs"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://rubbish-and-world.github.io/2021/10/05/CSAPP/Ch9/" data-id="clw33pwys001urtyqduendple" data-title="Ch9" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/10/09/CSAPP/malloclab/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          malloclab
        
      </div>
    </a>
  
  
    <a href="/2021/09/29/CSAPP/cachelab/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">cachelab</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Cryptography/">Cryptography</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Structure/">Data Structure</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Database/">Database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Electronics/">Electronics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/FrontEnd/">FrontEnd</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/FrontEnd/course/">course</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/IOT/">IOT</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LLL/">LLL</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/NTU/">NTU</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Stanford-CS229/">Stanford CS229</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Math/Discrete-Mathematics/">Discrete Mathematics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/Linear-Algebra/">Linear Algebra</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/Statistics/">Statistics</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Missing-Semester/">Missing Semester</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Networking/">Networking</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Networking/Stanford-CS144/">Stanford CS144</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/OS/">OS</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/OS/30DayOS/">30DayOS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/OS/TEP/">TEP</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python-OG/">Python OG</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Web3/">Web3</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/bis/">bis</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/csapp/">csapp</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/feeling/">feeling</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/feelings/">feelings</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/misc/">misc</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/noval/">noval</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/game/" rel="tag">game</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/game/" style="font-size: 10px;">game</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">November 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/05/17/feelings/crush/">crush</a>
          </li>
        
          <li>
            <a href="/2024/02/04/Bis/Core/">Core</a>
          </li>
        
          <li>
            <a href="/2024/01/29/miscellaneous/steal-video/">steal-video</a>
          </li>
        
          <li>
            <a href="/2024/01/01/feelings/2024/">2024</a>
          </li>
        
          <li>
            <a href="/2023/12/26/miscellaneous/RealWorld/">RealWorld</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 rubbish<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>