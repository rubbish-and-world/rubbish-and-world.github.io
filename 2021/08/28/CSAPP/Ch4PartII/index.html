<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Ch4PartII | rubbishbin</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });  4.4 General Principles of PipeliningSuch systems are familiar to anyone who has been through the serving line at a">
<meta property="og:type" content="article">
<meta property="og:title" content="Ch4PartII">
<meta property="og:url" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/index.html">
<meta property="og:site_name" content="rubbishbin">
<meta property="og:description" content="MathJax.Hub.Config({ tex2jax: {inlineMath: [[&#39;$&#39;, &#39;$&#39;]]}, messageStyle: &quot;none&quot; });  4.4 General Principles of PipeliningSuch systems are familiar to anyone who has been through the serving line at a">
<meta property="og:locale">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/unpip.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/pip.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/detailed.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/nonuniform.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/split.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/regdelay.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/dependency.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/ctrldepend.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/PCadaptation.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/seq+.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/pipline-.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/pipexample.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/prog1.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/prog2.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/prog3.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/prog4.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/bubble.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/fw1.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/fw2.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/fw3.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/loaduse.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/interlock.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/retbubble.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/misbreach.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/pcselection.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/decodeandwriteback.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/priorityexample.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/execstage.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/Mstage.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/detection.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/extensions.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/conditions.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/simultaneously.png">
<meta property="og:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/piplinecontrol.png">
<meta property="article:published_time" content="2021-08-28T04:51:33.000Z">
<meta property="article:modified_time" content="2021-09-03T07:35:07.254Z">
<meta property="article:author" content="rubbish">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/unpip.png">
  
    <link rel="alternate" href="/atom.xml" title="rubbishbin" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">rubbishbin</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Rechercher"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://rubbish-and-world.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CSAPP/Ch4PartII" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/28/CSAPP/Ch4PartII/" class="article-date">
  <time class="dt-published" datetime="2021-08-28T04:51:33.000Z" itemprop="datePublished">2021-08-28</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/csapp/">csapp</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Ch4PartII
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });</script>

<h2 id="4-4-General-Principles-of-Pipelining"><a href="#4-4-General-Principles-of-Pipelining" class="headerlink" title="4.4 General Principles of Pipelining"></a>4.4 General Principles of Pipelining</h2><p><em>Such systems are familiar to anyone who has been through the serving line at a cafeteria or run a car through an automated car wash.</em></p>
<a id="more"></a>

<ul>
<li> the task to be performed is <strong>divided into a series of discrete stages</strong></li>
<li> Rather than having one customer run through the entire sequence from beginning to end before the next can begin, we allow <strong>multiple customers to proceed through the system at once</strong></li>
<li>A key feature of pipelining is that it <strong>increases the throughput</strong> of the system(i.e., the number of customers served per unit time)</li>
<li>It may also slightly <strong>increase the latency</strong> (i.e., the time required to service an individual customer)</li>
</ul>
<h3 id="4-4-1-Computational-Pipelines"><a href="#4-4-1-Computational-Pipelines" class="headerlink" title="4.4.1 Computational Pipelines"></a>4.4.1 Computational Pipelines</h3><h5 id="Some-system-evaluation-property"><a href="#Some-system-evaluation-property" class="headerlink" title="Some system evaluation property"></a>Some system evaluation property</h5><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=3HIV4MnLGCw">video</a></p>
<ul>
<li><p>In contemporary logic design, we measure <strong>circuit delays</strong> in units of <strong>picoseconds</strong> (abbreviated “ps”), or $10^{−12}$ seconds</p>
</li>
<li><p>We express <strong>throughput</strong> in units of <strong>giga-instructions per second</strong> (abbreviated GIPS), or billions of instructions per second<br>$$<br>throughtput = \text{number of output item per second}<br>$$</p>
</li>
<li><p>The total time required to perform a single instruction from beginning to end is known as the <strong>latency</strong></p>
</li>
</ul>
<h5 id="Unpiplined-system"><a href="#Unpiplined-system" class="headerlink" title="Unpiplined system"></a>Unpiplined system</h5><p><img src="/2021/08/28/CSAPP/Ch4PartII/unpip.png" alt="unpiplined"></p>
<ul>
<li><p>we assume the combinational logic requires 300 ps, while the loading of the register requires 20 ps</p>
</li>
<li><p>In pipline digram:</p>
<ul>
<li>A series of instructions (here named I1, I2, and I3) are written from top to bottom.</li>
<li>time flows from left to right</li>
<li> The solid rectangles indicate the times during which these instructions are executed</li>
</ul>
</li>
<li><p>In this implementation, we must complete one instruction before beginning the next. Hence, the boxes do not overlap one another vertically</p>
</li>
</ul>
<h5 id="Piplined-system"><a href="#Piplined-system" class="headerlink" title="Piplined system"></a>Piplined system</h5><p><img src="/2021/08/28/CSAPP/Ch4PartII/pip.png" alt="pipline"></p>
<ul>
<li>Suppose we could divide the computation performed by our system into three stages, A, B, and C, where each requires 100 ps</li>
<li>we could cycle the clocks every 100 + 20 = 120 picoseconds, giving a throughput of around 8.33 GIPS.</li>
<li>Since processing a single instruction requires 3 clock cycles, the latency of this pipeline is 3 × 120 = 360 ps.</li>
<li> The increased latency is due to the time overhead of the added pipeline registers.</li>
</ul>
<h3 id="4-4-2-A-Detailed-Look-at-Pipeline-Operation"><a href="#4-4-2-A-Detailed-Look-at-Pipeline-Operation" class="headerlink" title="4.4.2 A Detailed Look at Pipeline Operation"></a>4.4.2 A Detailed Look at Pipeline Operation</h3><p><img src="/2021/08/28/CSAPP/Ch4PartII/detailed.png" alt="detailed pipline"></p>
<ul>
<li><p>We can see from this detailed view of pipeline operation that slowing down the clock would not change the pipeline behavior. </p>
</li>
<li><p>On the other hand, we could have disastrous effects if the clock were run too fast. </p>
</li>
<li><p>we see that the simple mechanism of having clocked registers between blocks of combinational logic suffices to control the flow of instructions in the pipeline</p>
</li>
</ul>
<h3 id="4-4-3-Limitations-of-Pipelining"><a href="#4-4-3-Limitations-of-Pipelining" class="headerlink" title="4.4.3 Limitations of Pipelining"></a>4.4.3 Limitations of Pipelining</h3><h5 id="Nonuniform-Partitioning"><a href="#Nonuniform-Partitioning" class="headerlink" title="Nonuniform Partitioning"></a>Nonuniform Partitioning</h5><p><em>the rate at which we can operate the clock is limited by the delay of the slowest stage</em></p>
<ul>
<li>Devising a partitioning of the system computation into a series of stages having uniform delays can be a major challenge for hardware designers.</li>
<li>some of the hardware units in a processor, such as the <strong>ALU</strong> and the memories, cannot be subdivided into multiple units with shorter delay.</li>
</ul>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/nonuniform.png" alt="nonuniform delay"></p>
<h4 id="Practice-Problem-4-28"><a href="#Practice-Problem-4-28" class="headerlink" title="Practice Problem 4.28"></a>Practice Problem 4.28</h4><blockquote>
<p>Suppose we analyze the combinational logic of Figure 4.32 and determine that it can be separated into a sequence of six blocks, named A to F, having delays of 80, 30, 60, 50, 70, and 10 ps, respectively, illustrated as follows:</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/split.png" alt="split"></p>
<p>We can create pipelined versions of this design by inserting pipeline registers between pairs of these blocks. Different combinations of pipeline depth (how many stages) and maximum throughput arise, depending on where we insert the pipeline registers. Assume that a pipeline register has a delay of 20 ps.</p>
<p>A. Inserting a single register gives a two-stage pipeline. Where should the register be inserted to maximize throughput? What would be the throughput and latency?</p>
<p>B. Where should two registers be inserted to maximize the throughput of a three-stage pipeline? What would be the throughput and latency?</p>
<p>C. Where should three registers be inserted to maximize the throughput of a 4-stage pipeline? What would be the throughput and latency?</p>
<p>D. What is the minimum number of stages that would yield a design with the maximum achievable throughput? Describe this design, its throughput, and its latency.</p>
</blockquote>
<h4 id="My-solution-white-check-mark"><a href="#My-solution-white-check-mark" class="headerlink" title="My solution : :white_check_mark:"></a>My solution : :white_check_mark:</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pipline</span>(<span class="params">maxdelay , stagenum</span>):</span></span><br><span class="line">    throughput =  ((<span class="number">1</span>/maxdelay) * <span class="number">10</span> ** <span class="number">12</span> ) / (<span class="number">1000</span>**<span class="number">3</span>)</span><br><span class="line">    latehcy =  maxdelay * stagenum</span><br><span class="line">    print(<span class="string">&quot;The throughput is &#123;&#125; GIPS&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>(throughput,<span class="number">2</span>)))</span><br><span class="line">    print(<span class="string">&quot;latehcy is &#123;&#125; ps&quot;</span>.<span class="built_in">format</span>(latehcy))</span><br></pre></td></tr></table></figure>
<p>A:</p>
<p>We try to split evenly, so insert between C and D. Then we have :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pipline(<span class="number">190</span>,<span class="number">2</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">The throughput is 5.26 GIPS</span></span><br><span class="line"><span class="string">latehcy is 380 ps</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>B:</p>
<p>Still try to split evenly in order to reduce the maxdelay, so we insert between B,C and D,E</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pipline(<span class="number">130</span>,<span class="number">3</span>)</span><br><span class="line">The throughput <span class="keyword">is</span> <span class="number">7.69</span> GIPS</span><br><span class="line">latehcy <span class="keyword">is</span> <span class="number">390</span> ps</span><br></pre></td></tr></table></figure>
<p>C:</p>
<p>insert the first one between A and B</p>
<p>insert the second one between C and D</p>
<p>insert the last one between D and E</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pipline(<span class="number">110</span> , <span class="number">4</span>)</span><br><span class="line">The throughput <span class="keyword">is</span> <span class="number">9.09</span> GIPS</span><br><span class="line">latehcy <span class="keyword">is</span> <span class="number">440</span> ps</span><br></pre></td></tr></table></figure>
<p>D:</p>
<p>the maximun throughput is given by split every stage except E and F</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>pipline(<span class="number">100</span> , <span class="number">5</span>)</span><br><span class="line">The throughput <span class="keyword">is</span> <span class="number">10.0</span> GIPS</span><br><span class="line">latehcy <span class="keyword">is</span> <span class="number">500</span> ps</span><br></pre></td></tr></table></figure>
<hr>
<h5 id="Diminishing-Returns-of-Deep-Pipelining"><a href="#Diminishing-Returns-of-Deep-Pipelining" class="headerlink" title="Diminishing Returns of Deep Pipelining"></a>Diminishing Returns of Deep Pipelining</h5><p><em>Modern processors employ very deep pipelines (15 or more stages) in an attempt to maximize the processor clock rate.</em></p>
<ul>
<li>The processor architects <strong>divide the instruction execution into a large number of very simple steps</strong> so that each stage can have a very small delay.</li>
<li>The circuit designers carefully <strong>design the pipeline registers to minimize their delay</strong></li>
<li>The chip designers must also carefully design the <strong>clock distribution network</strong> to ensure that the clock changes at the exact same time across the entire chip. </li>
</ul>
<h4 id="Practice-Problem-4-29"><a href="#Practice-Problem-4-29" class="headerlink" title="Practice Problem 4.29"></a>Practice Problem 4.29</h4><blockquote>
<p>Suppose we could take the system of Figure 4.32 and divide it into an arbitrary number of pipeline stages k, each having a delay of 300/k, and with each pipeline register having a delay of 20 ps.</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/regdelay.png" alt="register load delay"></p>
<p>A. What would be the latency and the throughput of the system, as functions of k?</p>
<p>B. What would be the ultimate limit on the throughput?</p>
</blockquote>
<h4 id="My-solution"><a href="#My-solution" class="headerlink" title="My solution :"></a>My solution :</h4><p>A:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pipline(<span class="number">300</span>/k+<span class="number">20</span> , k)</span><br></pre></td></tr></table></figure>
<p>B:</p>
<p>the delay of register</p>
<h4 id="Solution-on-the-book"><a href="#Solution-on-the-book" class="headerlink" title="Solution on the book:"></a>Solution on the book:</h4><p>B:As we let k go to infinity, the throughput becomes 1,000/20 = 50 GIPS. Of course, the latency would approach infinity as well.</p>
<p>As we try to subdivide the logic into many stages, the latency of the pipeline registers becomes a limiting factor.</p>
<h3 id="4-4-4-Pipelining-a-System-with-Feedback"><a href="#4-4-4-Pipelining-a-System-with-Feedback" class="headerlink" title="4.4.4 Pipelining a System with Feedback"></a>4.4.4 Pipelining a System with Feedback</h3><p><em>For a system that executes machine programs such as x86-64 or Y86-64, there are potential dependencies between successive instructions.</em></p>
<h5 id="data-dependency"><a href="#data-dependency" class="headerlink" title="data dependency"></a>data dependency</h5><p><img src="/2021/08/28/CSAPP/Ch4PartII/dependency.png" alt="dependency"></p>
<h5 id="control-dependency"><a href="#control-dependency" class="headerlink" title="control dependency"></a>control dependency</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">loop:</span><br><span class="line"> subq %rdx,%rbx</span><br><span class="line"> jne targ</span><br><span class="line"> irmovq $10,%rdx</span><br><span class="line"> jmp loop</span><br><span class="line">targ:</span><br><span class="line"> halt</span><br></pre></td></tr></table></figure>
<p>the outcome of the conditional test determines whether the next instruction to execute will be the irmovq instruction (line 4) or the halt instruction (line 7)</p>
<p>In our design for SEQ, these dependencies were handled by the feedback paths shown on the right-hand side of Figure 4.22.</p>
<p>However, if we attempt to convert this to a three-stage pipeline in the most straightforward manner (Figure 4.38(c)), we change the behavior of the system.(the result of I1 becomes an input to I4)</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/ctrldepend.png" alt="control dependency"></p>
<hr>
<p> Somehow we must deal with the data and control dependencies between instructions so that the resulting behavior matches the model defined by the ISA.</p>
<hr>
<h2 id="4-5-Pipelined-Y86-64-Implementations"><a href="#4-5-Pipelined-Y86-64-Implementations" class="headerlink" title="4.5 Pipelined Y86-64 Implementations"></a>4.5 Pipelined Y86-64 Implementations</h2><p><em>We are finally ready for the major task of this chapter—designing a pipelined Y86- 64 processor</em></p>
<h3 id="4-5-1-SEQ-Rearranging-the-Computation-Stages"><a href="#4-5-1-SEQ-Rearranging-the-Computation-Stages" class="headerlink" title="4.5.1 SEQ+: Rearranging the Computation Stages"></a>4.5.1 SEQ+: Rearranging the Computation Stages</h3><p><em>As a transitional step toward a pipelined design, we must slightly rearrange the order of the five stages in SEQ so that the <strong>PC update stage comes at the beginning of the clock cycle, rather than at the end</strong>.</em>(We refer to this modified design as SEQ+.)</p>
<p>We can move the PC update stage so that its logic is active at the beginning of the clock cycle by making it compute the PC value for the <strong>current</strong> instruction</p>
<p>With SEQ+ (Figure 4.39(b)), we create state registers to hold the signals computed during an instruction(previous instruction)</p>
<p>Then, as a new clock cycle begins, the values propagate through the exact same logic to compute the PC for the now-current instruction.</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/PCadaptation.png" alt="new PC computation scheme"></p>
<blockquote>
<p>One curious feature of SEQ+ is that there is no hardware register storing the program counter. Instead, the PC is computed dynamically based on some state information stored from the previous instruction.</p>
<p>This is a small illustration of the fact that we can implement a processor in a way that differs from the conceptual model implied by the ISA, as long as the processor correctly executes arbitrary machinelanguage programs. </p>
</blockquote>
<p>The shift of state elements from SEQ to SEQ+ is an example of a general transformation known as <strong>circuit retiming</strong></p>
<p>Retiming changes the state representation for a system without changing its logical behavior. It is often used to balance the delays between the different stages of a pipelined system.</p>
<h3 id="4-5-2-Inserting-Pipeline-Registers"><a href="#4-5-2-Inserting-Pipeline-Registers" class="headerlink" title="4.5.2 Inserting Pipeline Registers"></a>4.5.2 Inserting Pipeline Registers</h3><p>The pipeline registers are shown in this figure as <strong>blue boxes</strong>, each containing different fields that are shown as white boxes. As indicated by the multiple fields, each pipeline register holds multiple bytes and words. </p>
<p>white boxes represent actual hardware components rather than labels</p>
<ul>
<li><code>F</code> holds a predicted value of the program counter</li>
<li><code>D</code> sits between the fetch and decode stages. It holds information about the most recently fetched instruction for processing by the decode stage</li>
<li><code>E</code> sits between the decode and execute stages. It holds information about the most recently decoded instruction and the values read from the register file for processing by the execute stage.</li>
<li><code>M</code> sits between the execute and memory stages. It holds the results of the most recently executed instruction for processing by the memory stage. It also holds information about branch conditions and branch targets for processing conditional jumps.</li>
<li><code>W</code> sits between the memory stage and the feedback paths that supply the computed results to the register file for writing and the return address to the PC selection logic when completing a ret instruction.</li>
</ul>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/seq+.png" alt="seq plus"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/pipline-.png" alt="pipline minus"></p>
<p>Then our code execution will be like</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/pipexample.png" alt="pipline execution example"></p>
<p>Since normal <strong>program flow goes from top to bottom</strong> of a listing, we preserve this ordering by having the <strong>pipeline flow go from bottom to top</strong>. </p>
<h3 id="4-5-3-Rearranging-and-Relabeling-Signals"><a href="#4-5-3-Rearranging-and-Relabeling-Signals" class="headerlink" title="4.5.3 Rearranging and Relabeling Signals"></a>4.5.3 Rearranging and Relabeling Signals</h3><blockquote>
<p>Aside </p>
<p>What is the difference between signals M_stat and m_stat? </p>
<p>With our naming system, the uppercase prefixes ‘D’, ‘E’, ‘M’, and ‘W’ refer to pipeline registers, and so M_stat refers to the status code field of pipeline register M. </p>
<p>The lowercase prefixes ‘f’, ‘d’, ‘e’, ‘m’, and ‘w’ refer to the pipeline stages, and so m_stat refers to the status signal generated in the memory stage by a control logic block. </p>
<p>Understanding this naming convention is critical to understanding the operation of our pipelined processors.</p>
</blockquote>
<h3 id="4-5-4-Next-PC-Prediction"><a href="#4-5-4-Next-PC-Prediction" class="headerlink" title="4.5.4 Next PC Prediction"></a>4.5.4 Next PC Prediction</h3><p>In pipline, we must determine the location of the next instruction right after fetching the current instruction.</p>
<p>Unfortunately, if the instruction is <code>ret</code> or conditional branch, we cannot determine the address of next instruction until execution stage or memory stage</p>
<p>Except these two instructions, the address of the next instruction can be predicated based on information computed during the fetch stage.</p>
<p>We can therefore achieve our goal of issuing a new instruction every clock cycle in most cases by predicting the next value of the PC.</p>
<p>Extensive experiments have been conducted on effective strategies for predicting whether or not branches will be taken(and large amount of hardware to implement them)</p>
<p>In our design, we simply assume all condition is taken for branches.</p>
<p>For <code>ret</code> instruction, we just stop fetch new instruction until the <code>ret</code> is finished.</p>
<h3 id="4-5-5-Pipeline-Hazards"><a href="#4-5-5-Pipeline-Hazards" class="headerlink" title="4.5.5 Pipeline Hazards"></a>4.5.5 Pipeline Hazards</h3><p>Resulted from dependencies, hazards can be classified as either data hazards or control hazards</p>
<h4 id="Data-hazard"><a href="#Data-hazard" class="headerlink" title="Data hazard"></a>Data hazard</h4><p><img src="/2021/08/28/CSAPP/Ch4PartII/prog1.png" alt="prog1"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/prog2.png" alt="prog2"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/prog3.png" alt="prog3"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/prog4.png" alt="prog4"></p>
<p><em>These examples illustrate that a data hazard can arise for an instruction when one of its operands is updated by any of the three preceding instructions. These hazards occur because our pipelined processor reads the operands for an instruction from the register file in the decode stage but does not write the results for the instruction to the register file until three cycles later, after the instruction passes through the write-back stage.</em></p>
<h4 id="Avoiding-Data-Hazards-by-Stalling"><a href="#Avoiding-Data-Hazards-by-Stalling" class="headerlink" title="Avoiding Data Hazards by Stalling"></a>Avoiding Data Hazards by Stalling</h4><p><em>One very general technique for avoiding hazards involves stalling, where the <strong>processor holds back one or more instructions in the pipeline</strong> until the hazard condition no longer holds</em></p>
<ul>
<li>It involves simple enhancements to the pipeline control logic</li>
<li>it has the same effect like adding <code>nop</code> instruction, which has shown above</li>
</ul>
<p>For example</p>
<p>When the addq instruction is in the decode stage, the pipeline control logic detects that at least one of the instructions in the execute, memory, or write-back stage will update either register %rdx or register %rax. Rather than letting the addq instruction pass through the stage with the incorrect results, it stalls the instruction, holding it back in the decode stage for either one (for prog2) or three (for prog4) extra cycles.</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/bubble.png" alt="insert bubble"></p>
<p>(We also need to keep PC a fixed value when stalling)</p>
<p><strong>This mechanism can be implemented fairly easily, but the resulting performance is not very good</strong></p>
<p>There are numerous cases in which one instruction updates a register and a closely following instruction uses the same register. This will cause the pipeline to stall for up to three cycles, reducing the overall throughput significantly</p>
<h4 id="Avoiding-Data-Hazards-by-Forwarding"><a href="#Avoiding-Data-Hazards-by-Forwarding" class="headerlink" title="Avoiding Data Hazards by Forwarding"></a>Avoiding Data Hazards by Forwarding</h4><p><em>If there are register to be updated, <strong>forwarding the pended value in previous stages to register access result</strong></em></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/fw1.png" alt="forwarding example"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/fw2.png" alt="forwarding example"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/fw3.png" alt="forwarding example"></p>
<p>This gives a total of five different forwarding sources (e_valE, m_valM, M_valE, W_valM, and W_valE) and two different forwarding destinations (valA and valB).</p>
<ul>
<li>This technique of passing a result value directly from one pipeline stage to an earlier one is commonly known as data forwarding</li>
<li>Data forwarding requires <strong>adding additional data connections and control logic to the basic hardware structure</strong>.</li>
</ul>
<h4 id="Load-Use-Data-Hazards"><a href="#Load-Use-Data-Hazards" class="headerlink" title="Load/Use Data Hazards"></a>Load/Use Data Hazards</h4><p>Forwarding cannot handle the situation that the value used to update the register is read from memory, since it must wait for the value to be read.</p>
<p>we can avoid a load/use data hazard with <strong>a combination of stalling and forwarding</strong></p>
<p>This requires <strong>modifications of the control logic</strong>, but it can use existing bypass paths</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/loaduse.png" alt="load/use hazard"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/interlock.png" alt="interlock"></p>
<p><em>This use of a stall to handle a load/use hazard is called a load <strong>interlock</strong>.</em></p>
<p>Load interlocks combined with forwarding suffice to handle all possible forms of data hazards. Since only load interlocks reduce the pipeline throughput, we can nearly achieve our throughput goal of issuing one new instruction on every clock cycle.</p>
<h4 id="Avoiding-Control-Hazards"><a href="#Avoiding-Control-Hazards" class="headerlink" title="Avoiding Control Hazards"></a>Avoiding Control Hazards</h4><p><em>Control hazards arise <strong>when the processor cannot reliably determine the address of the next instruction based on the current instruction</strong> in the fetch stage.</em></p>
<h4 id="ret-hazard"><a href="#ret-hazard" class="headerlink" title="ret hazard"></a><code>ret</code> hazard</h4><p>For example when executing the following codes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">0x000: irmovq stack,%rsp # Initialize stack pointer</span><br><span class="line">0x00a: call proc # Procedure call</span><br><span class="line">0x013: irmovq $10,%rdx # Return point</span><br><span class="line">0x01d: halt</span><br><span class="line">0x020: .pos 0x20</span><br><span class="line">0x020: proc: # proc:</span><br><span class="line">0x020: ret # Return immediately</span><br><span class="line">0x021: rrmovq %rdx,%rbx # Not executed</span><br><span class="line">0x030: .pos 0x30</span><br><span class="line">0x030: stack: # stack: Stack pointer</span><br></pre></td></tr></table></figure>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/retbubble.png" alt="ret instruction stall"></p>
<p>Once the ret instruction reaches the write-back stage, the PC selection logic will set the program counter to the return address, and therefore the fetch stage will fetch the irmovq instruction at the return point</p>
<h4 id="Mispredicate-hazard"><a href="#Mispredicate-hazard" class="headerlink" title="Mispredicate hazard"></a>Mispredicate hazard</h4><p>For example</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0x000: xorq %rax,%rax</span><br><span class="line">0x002: jne target # Not taken</span><br><span class="line">0x00b: irmovq $1, %rax # Fall through</span><br><span class="line">0x015: halt</span><br><span class="line">0x016: target:</span><br><span class="line">0x016: irmovq $2, %rdx # Target</span><br><span class="line">0x020: irmovq $3, %rbx # Target+1</span><br><span class="line">0x02a: halt</span><br></pre></td></tr></table></figure>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/misbreach.png" alt="misbreach"></p>
<ul>
<li>Since the jump instruction is predicted as being taken, the instruction at the jump target will be fetched in cycle 3</li>
<li> By the time the branch logic detects that the jump should not be taken during cycle 4, two instructions have been fetched that should not continue being executed</li>
<li>Fortunately, neither of these instructions has caused a change in the programmer-visible state(Not reach the execution stage)</li>
<li>the pipeline can simply cancel the two misfetched instructions by <strong>injecting bubbles into the decode and execute stages on the following cycle</strong> while also fetching the instruction following the jump instruction.</li>
<li>The two misfetched instructions will then simply disappear from the pipeline and therefore not have any effect on the programmer-visible state. </li>
</ul>
<p><strong><em>a simple extension to the basic clocked register design will enable us to stall stages and to inject bubbles into pipeline registers as part of the pipeline control logic.</em></strong></p>
<h3 id="4-5-6-Exception-Handling"><a href="#4-5-6-Exception-Handling" class="headerlink" title="4.5.6 Exception Handling"></a>4.5.6 Exception Handling</h3><p><em>a variety of activities in a processor can lead to exceptional control flow, where the <strong>normal chain of program execution gets broken</strong>.</em></p>
<ul>
<li><p>Exceptions can be generated either internally, by the executing program, or externally, by some outside signal.</p>
</li>
<li><p>A more complete processor design would also handle external exceptions, such as when the processor receives a signal that the network interface has received a new packet or the user has clicked a mouse button</p>
<p>(Handling exceptions correctly is a challenging aspect of any microprocessor design. They can occur at unpredictable times, and they require creating a clean break in the flow of instructions through the processor pipeline)</p>
</li>
<li><p>It should appear that all instructions up to the excepting instruction have completed, but none of the following instructions should have any effect on the <em>programmer-visible state</em>.</p>
</li>
<li><p>In a more complete design, the processor would continue by invoking an exception handler, a procedure that is part of the operating system</p>
</li>
</ul>
<p>In a pipelined system, exception handling involves several subtleties.</p>
<ul>
<li><p>It is possible to have exceptions triggered by multiple instructions simultaneously</p>
<p>For example, in one clock cycle, fetch stage fetchs a <code>halt</code> and memory stage has a <code>invalid memory address</code></p>
<p>So which exception should we report?</p>
<p>The basic rule is to put priority on the exception triggered by the instruction that is furthest along the pipeline</p>
<p>(In terms of the machine-language program, the instruction in the memory stage should appear to execute before one in the fetch stage, and therefore only this exception should be reported to the operating system.)</p>
</li>
<li><p>When an instruction first fetched and begins execution, causes an exception, and later is canceled due to a mispredicted branch.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0x000: 6300 | xorq %rax,%rax</span><br><span class="line">0x002: 741600000000000000 | jne target # Not taken</span><br><span class="line">0x00b: 30f00100000000000000 | irmovq $1, %rax # Fall through</span><br><span class="line">0x015: 00 | halt</span><br><span class="line">0x016: | target:</span><br><span class="line">0x016: ff | .byte 0xFF # Invalid instruction code</span><br></pre></td></tr></table></figure>
<p>​    The pipeline control logic will cancel the invalid instruction, but we want to avoid raising an exception.</p>
</li>
<li><p>It is possible for an instruction following one causing an exception to alter some part of the state before the excepting was detected</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">irmovq $1,%rax</span><br><span class="line"> xorq %rsp,%rsp # Set stack pointer to 0 and CC to 100</span><br><span class="line"> pushq %rax # Attempt to write to 0xfffffffffffffff8, detected in memory stage</span><br><span class="line"> addq %rax,%rax # (Should not be executed) Would set CC to 000</span><br></pre></td></tr></table></figure>
<p>we can both correctly choose among the different exceptions and avoid raising exceptions for instructions that are fetched due to mispredicted branches by <strong>merging the exception-handling logic into the pipeline structure</strong>. That is the <strong>motivation for us to include a status code statin each of our pipeline registers</strong></p>
</li>
</ul>
<p>If an instruction generates an exception at some stage in its processing, the status field is set to indicate the nature of the exception. The exception status propagates through the pipeline with the rest of the information for that instruction, <strong>until it reaches the write-back stage</strong>. <strong>At this point, the pipeline control logic detects the occurrence of the exception and stops execution</strong>.</p>
<p>The simple rule of <strong>carrying the exception status together with all other information about an instruction through the pipeline</strong> provides a simple and reliable mechanism for handling exceptions.</p>
<ul>
<li><p>The pipline like a queue, FIFO, so it follows the order indicated by assembly language</p>
</li>
<li><p>When reach write back stage and an exception was detected, the processor will disable any updating of the programmer-visible state (the condition code register and the memory) by later instructions in the pipeline(make those devices unwritable)</p>
</li>
<li><p>If some instruction is fetched but later canceled, any exception status information about the instruction gets canceled as well.</p>
</li>
</ul>
<h3 id="4-5-7-PIPE-Stage-Implementations"><a href="#4-5-7-PIPE-Stage-Implementations" class="headerlink" title="4.5.7 PIPE Stage Implementations"></a>4.5.7 PIPE Stage Implementations</h3><p><em>Many of the logic blocks are identical to their counterparts in SEQ and SEQ+, except that we must <strong>choose proper versions of the different signals</strong> from the pipeline registers (written with the pipeline register name, written in uppercase, as a prefix) or from the stage computations (written with the first character of the stage name, written in lowercase, as a prefix).</em></p>
<p>the complete HCL code for PIPE is given in Web Aside arch:hcl on page 508.</p>
<h4 id="PC-Selection-and-Fetch-Stage"><a href="#PC-Selection-and-Fetch-Stage" class="headerlink" title="PC Selection and Fetch Stage"></a>PC Selection and Fetch Stage</h4><p><em>The PC selection logic <strong>chooses between three program counter sources</strong></em></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/pcselection.png" alt="PC select"></p>
<h4 id="Decode-and-Write-Back-Stages"><a href="#Decode-and-Write-Back-Stages" class="headerlink" title="Decode and Write-Back Stages"></a>Decode and Write-Back Stages</h4><p><em>we want the writes to occur to the destination registers specified by the instruction in the write-back stage</em></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/decodeandwriteback.png" alt="pic"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">word d_valA = [</span><br><span class="line">D_icode <span class="keyword">in</span> &#123; ICALL, IJXX &#125; : D_valP; <span class="comment"># Use incremented PC</span></span><br><span class="line">d_srcA == e_dstE : e_valE; <span class="comment"># Forward valE from execute</span></span><br><span class="line">d_srcA == M_dstM : m_valM; <span class="comment"># Forward valM from memory</span></span><br><span class="line">d_srcA == M_dstE : M_valE; <span class="comment"># Forward valE from memory</span></span><br><span class="line">d_srcA == W_dstM : W_valM; <span class="comment"># Forward valM from write back</span></span><br><span class="line">d_srcA == W_dstE : W_valE; <span class="comment"># Forward valE from write back</span></span><br><span class="line"><span class="number">1</span> : d_rvalA; <span class="comment"># Use value read from register file</span></span><br><span class="line">];</span><br></pre></td></tr></table></figure>
<p>The priority given to the five forwarding sources in the above HCL code is very important.</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/priorityexample.png" alt="priority"></p>
<h4 id="Execute-Stage"><a href="#Execute-Stage" class="headerlink" title="Execute Stage"></a>Execute Stage</h4><p><em>The hardware units and the logic blocks are identical to those in SEQ, with an appropriate renaming of signals.</em></p>
<p>One difference is that the logic labeled “Set CC,” which determines whether or not to update the condition codes, has signals m_stat and W_stat as inputs.</p>
<p>These signals are used to detect cases where an instruction causing an exception is passing through later pipeline stages, and therefore any updating of the condition codes should be suppressed</p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/execstage.png" alt="execute stage"></p>
<h4 id="Memory-Stage"><a href="#Memory-Stage" class="headerlink" title="Memory Stage"></a>Memory Stage</h4><p><img src="/2021/08/28/CSAPP/Ch4PartII/Mstage.png" alt="Mstage"></p>
<h3 id="4-5-8-Pipeline-Control-Logic"><a href="#4-5-8-Pipeline-Control-Logic" class="headerlink" title="4.5.8 Pipeline Control Logic"></a>4.5.8 Pipeline Control Logic</h3><p><em>We are now ready to complete our design for PIPE by creating the pipeline control logic.</em></p>
<p>Only 4 problems left:</p>
<ul>
<li>Load/use hazards.</li>
<li>Processing ret.</li>
<li>Mispredicted branches.</li>
<li>Exceptions</li>
</ul>
<h4 id="Desired-Handling-of-Special-Control-Cases"><a href="#Desired-Handling-of-Special-Control-Cases" class="headerlink" title="Desired Handling of Special Control Cases"></a>Desired Handling of Special Control Cases</h4><p><em>In summary, implementing this pipeline flow requires detecting the hazard condition, keeping pipeline registers F and D fixed, and injecting a bubble into the execute stage.</em></p>
<h4 id="Detecting-Special-Control-Conditions"><a href="#Detecting-Special-Control-Conditions" class="headerlink" title="Detecting Special Control Conditions"></a>Detecting Special Control Conditions</h4><p><img src="/2021/08/28/CSAPP/Ch4PartII/detection.png" alt="detection"></p>
<h4 id="Pipeline-Control-Mechanisms"><a href="#Pipeline-Control-Mechanisms" class="headerlink" title="Pipeline Control Mechanisms"></a>Pipeline Control Mechanisms</h4><p><em>These mechanisms involve small extensions to the basic clocked register described</em></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/extensions.png" alt="extensions"></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/conditions.png" alt="different conditions"></p>
<h4 id="Combinations-of-Control-Conditions"><a href="#Combinations-of-Control-Conditions" class="headerlink" title="Combinations of Control Conditions"></a>Combinations of Control Conditions</h4><p><em>A common bug in designing a system is to fail to handle instances where multiple special conditions arise <strong>simultaneously</strong></em></p>
<p><img src="/2021/08/28/CSAPP/Ch4PartII/simultaneously.png" alt="simltaneously"></p>
<p>We can see by these diagrams that most of the control conditions are mutually exclusive.Only the two combinations indicated by arrows can arise simultaneously.</p>
<p>The pipeline control logic should detect that the branch was mispredicted and therefore cancel the ret instruction</p>
<h4 id="Control-Logic-Implementation"><a href="#Control-Logic-Implementation" class="headerlink" title="Control Logic Implementation"></a>Control Logic Implementation</h4><p><img src="/2021/08/28/CSAPP/Ch4PartII/piplinecontrol.png" alt="pipline control logic"></p>
<h3 id="4-5-9-Performance-Analysis"><a href="#4-5-9-Performance-Analysis" class="headerlink" title="4.5.9 Performance Analysis"></a>4.5.9 Performance Analysis</h3><p><em>We can measure the inefficiency by determining <strong>how often a bubble gets injected into the pipeline</strong>, since these cause unused pipeline cycles.</em></p>
<p>We can quantify the effect these penalties have on the overall performance by computing an estimate of the average number of clock cycles PIPE would require per instruction it executes, a measure known as the <strong>CPI</strong> </p>
<blockquote>
<p>How do we know our implementation of ISA is correct? We cannot test all combinations of instructions since they are nearly infinite.</p>
<p>Newer methods of <strong>formal verification</strong>, however, hold the promise that we can have tools that rigorously consider all possible behaviors of a system and determine whether or not there are any design errors</p>
</blockquote>
<h3 id="4-5-10-Unfinished-Business"><a href="#4-5-10-Unfinished-Business" class="headerlink" title="4.5.10 Unfinished Business"></a>4.5.10 Unfinished Business</h3><p><em>Still, PIPE lacks several key features that would be required in an actual microprocessor design.</em></p>
<h4 id="Multicycle-Instructions"><a href="#Multicycle-Instructions" class="headerlink" title="Multicycle Instructions"></a>Multicycle Instructions</h4><p><em>In a more complete instruction set, we would also need to implement instructions requiring more complex operations such as integer multiplication and division and floating-point operations</em></p>
<h4 id="Interfacing-with-the-Memory-System"><a href="#Interfacing-with-the-Memory-System" class="headerlink" title="Interfacing with the Memory System"></a>Interfacing with the Memory System</h4><ul>
<li>We  ignored the possible hazards caused by self-modifying code where one instruction writes to the region of memory from which later instructions are fetched. </li>
<li>we reference memory locations according to their virtual addresses, and these require a translation into physical addresses before the actual read or write operation can be performed.(So more than one clock cycle was needed)</li>
</ul>
<p>However, using a <strong>combination of TLBs and caches</strong>, it is indeed <strong>possible to read instructions and read or write data in a single clock cycle</strong> most of the time.</p>
<p>But still there will be two type of memory reference delay</p>
<ol>
<li><p>cache miss</p>
<p>The value to be refered is not in cache, but can be retrieved from a higher-level cache or from the main memory of the processor, requiring 3 to 20 clock cycles.</p>
<p><strong>the pipeline simply stalls</strong>, holding the instruction in the fetch or memory stage until the cache can perform the read or write operation</p>
</li>
<li><p>page fault</p>
<p>In some cases, the memory location being referenced is actually stored in the disk or nonvolatile memory</p>
<p>this will cause the processor to invoke the <strong>operating system’s exception handler code</strong>.</p>
<p> This code will then set up a transfer from the disk to the main memory. Once this completes, the operating system will return to the original program, where the instruction causing the page fault will be re-executed.</p>
<p>Since accessing a disk can require millions of clock cycles, the several thousand cycles of processing performed by the OS page fault handler has little impact on performance.</p>
</li>
</ol>
<h2 id="4-6-Summary"><a href="#4-6-Summary" class="headerlink" title="4.6 Summary"></a>4.6 Summary</h2><p><em>In this chapter, we have learned several important lessons about processor design:</em></p>
<ul>
<li><p><strong>Managing complexity is a top priority</strong>. We want to make optimum use of the hardware resources to get maximum performance at minimum cost.</p>
</li>
<li><p><strong>We do not need to implement the ISA directly</strong>. A direct implementation of the ISA would imply a very sequential design, We can indirectly implement it by using pipline.</p>
<p>By careful design and analysis, we can handle the various pipeline hazards, so that the overall effect of running a program exactly matches what would be obtained with the ISA model.</p>
</li>
<li><p><strong>Hardware designers must be meticulous</strong>. Once a chip has been fabricated, it is nearly impossible to correct any errors</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://rubbish-and-world.github.io/2021/08/28/CSAPP/Ch4PartII/" data-id="cl1otyss9000eghyqgn3o9bem" data-title="Ch4PartII" class="article-share-link">Partager</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/09/03/CSAPP/architecturelab/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          architecturelab
        
      </div>
    </a>
  
  
    <a href="/2021/08/20/CSAPP/Ch4/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">Ch4</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Cryptography/">Cryptography</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Structure/">Data Structure</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Database/">Database</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Electronics/">Electronics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/NTU/">NTU</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Stanford-CS229/">Stanford CS229</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Math/Discrete-Mathematics/">Discrete Mathematics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/Linear-Algebra/">Linear Algebra</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Missing-Semester/">Missing Semester</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Networking/">Networking</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Networking/Stanford-CS144/">Stanford CS144</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/OS/">OS</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/OS/30DayOS/">30DayOS</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python-OG/">Python OG</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/csapp/">csapp</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/feelings/">feelings</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/misc/">misc</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/noval/">noval</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Mot-clés</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/game/" rel="tag">game</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Nuage de mot-clés</h3>
    <div class="widget tagcloud">
      <a href="/tags/game/" style="font-size: 10px;">game</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">May 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">April 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">July 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/06/26/miscellaneous/ExtendGDBviaPy/">ExtendGDBviaPy</a>
          </li>
        
          <li>
            <a href="/2022/06/17/miscellaneous/K-RTheCPL/">K&amp;RTheCPL</a>
          </li>
        
          <li>
            <a href="/2022/06/11/feelings/Origin/">Origin</a>
          </li>
        
          <li>
            <a href="/2022/05/24/feelings/Civilization/">Civilization</a>
          </li>
        
          <li>
            <a href="/2022/05/12/DataStructure/FordFulkerson/">FordFulkerson</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 rubbish<br>
      Propulsé par <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>